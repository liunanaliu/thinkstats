<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Thinking for the 21st Century</title>
  <meta name="description" content="Statistical Thinking for the 21st Century">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Thinking for the 21st Century" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="poldrack/psych10-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Thinking for the 21st Century" />
  
  
  

<meta name="author" content="Copyright 2018 Russell A. Poldrack">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="the-general-linear-model.html">
<link rel="next" href="practical-example.html">
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="book_assets/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="book_assets/viz-0.3/viz.js"></script>
<link href="book_assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="book_assets/grViz-binding-1.0.0/grViz.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129414074-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129414074-1');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#why-does-this-book-exist"><i class="fa fa-check"></i><b>0.1</b> Why does this book exist?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#youre-not-a-statistician---why-should-we-listen-to-you"><i class="fa fa-check"></i><b>0.2</b> You’re not a statistician - why should we listen to you?</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#why-r"><i class="fa fa-check"></i><b>0.3</b> Why R?</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#the-golden-age-of-data"><i class="fa fa-check"></i><b>0.4</b> The golden age of data</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#an-open-source-book"><i class="fa fa-check"></i><b>0.5</b> An open source book</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-statistical-thinking"><i class="fa fa-check"></i><b>1.1</b> What is statistical thinking?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-can-statistics-do-for-us"><i class="fa fa-check"></i><b>1.2</b> What can statistics do for us?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#fundamental-concepts-of-statistics"><i class="fa fa-check"></i><b>1.3</b> Fundamental concepts of statistics</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#learning-from-data"><i class="fa fa-check"></i><b>1.3.1</b> Learning from data</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#aggregation"><i class="fa fa-check"></i><b>1.3.2</b> Aggregation</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#uncertainty"><i class="fa fa-check"></i><b>1.3.3</b> Uncertainty</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#sampling"><i class="fa fa-check"></i><b>1.3.4</b> Sampling</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#causality-and-statistics"><i class="fa fa-check"></i><b>1.4</b> Causality and statistics</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#suggested-readings"><i class="fa fa-check"></i><b>1.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="working-with-data.html"><a href="working-with-data.html"><i class="fa fa-check"></i><b>2</b> Working with data</a><ul>
<li class="chapter" data-level="2.1" data-path="working-with-data.html"><a href="working-with-data.html#what-are-data"><i class="fa fa-check"></i><b>2.1</b> What are data?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="working-with-data.html"><a href="working-with-data.html#qualitative-data"><i class="fa fa-check"></i><b>2.1.1</b> Qualitative data</a></li>
<li class="chapter" data-level="2.1.2" data-path="working-with-data.html"><a href="working-with-data.html#quantitative-data"><i class="fa fa-check"></i><b>2.1.2</b> Quantitative data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="working-with-data.html"><a href="working-with-data.html#scales-of-measurement"><i class="fa fa-check"></i><b>2.2</b> Scales of measurement</a><ul>
<li class="chapter" data-level="2.2.1" data-path="working-with-data.html"><a href="working-with-data.html#why-do-scales-of-measurement-matter"><i class="fa fa-check"></i><b>2.2.1</b> Why do scales of measurement matter?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="working-with-data.html"><a href="working-with-data.html#what-makes-a-good-measurement"><i class="fa fa-check"></i><b>2.3</b> What makes a good measurement?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="working-with-data.html"><a href="working-with-data.html#reliability"><i class="fa fa-check"></i><b>2.3.1</b> <em>Reliability</em></a></li>
<li class="chapter" data-level="2.3.2" data-path="working-with-data.html"><a href="working-with-data.html#validity"><i class="fa fa-check"></i><b>2.3.2</b> <em>Validity</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="working-with-data.html"><a href="working-with-data.html#suggested-readings-1"><i class="fa fa-check"></i><b>2.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#what-is-probability"><i class="fa fa-check"></i><b>3.1</b> What is probability?</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#how-do-we-determine-probabilities"><i class="fa fa-check"></i><b>3.2</b> How do we determine probabilities?</a><ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#personal-opinion"><i class="fa fa-check"></i><b>3.2.1</b> Personal opinion</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#empirical-frequency"><i class="fa fa-check"></i><b>3.2.2</b> Empirical frequency</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2.3</b> Classical probability</a></li>
<li class="chapter" data-level="3.2.4" data-path="probability.html"><a href="probability.html#solving-de-meres-problem"><i class="fa fa-check"></i><b>3.2.4</b> Solving de Méré’s problem</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>3.3</b> Probability distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="probability.html"><a href="probability.html#cumulative-probability-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Cumulative probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.4</b> Conditional probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#computing-conditional-probabilities-from-data"><i class="fa fa-check"></i><b>3.5</b> Computing conditional probabilities from data</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>3.6</b> Independence</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#bayestheorem"><i class="fa fa-check"></i><b>3.7</b> Reversing a conditional probability: Bayes’ rule</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#learning-from-data-1"><i class="fa fa-check"></i><b>3.8</b> Learning from data</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#odds-and-odds-ratios"><i class="fa fa-check"></i><b>3.9</b> Odds and odds ratios</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#what-do-probabilities-mean"><i class="fa fa-check"></i><b>3.10</b> What do probabilities mean?</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#suggested-readings-2"><i class="fa fa-check"></i><b>3.11</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>4</b> Summarizing data</a><ul>
<li class="chapter" data-level="4.1" data-path="summarizing-data.html"><a href="summarizing-data.html#why-summarize-data"><i class="fa fa-check"></i><b>4.1</b> Why summarize data?</a></li>
<li class="chapter" data-level="4.2" data-path="summarizing-data.html"><a href="summarizing-data.html#summarizing-data-using-tables"><i class="fa fa-check"></i><b>4.2</b> Summarizing data using tables</a><ul>
<li class="chapter" data-level="4.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#frequency-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Frequency distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#cumulative-distributions"><i class="fa fa-check"></i><b>4.2.2</b> Cumulative distributions</a></li>
<li class="chapter" data-level="4.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#plotting-histograms"><i class="fa fa-check"></i><b>4.2.3</b> Plotting histograms</a></li>
<li class="chapter" data-level="4.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#histogram-bins"><i class="fa fa-check"></i><b>4.2.4</b> Histogram bins</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="summarizing-data.html"><a href="summarizing-data.html#idealized-representations-of-distributions"><i class="fa fa-check"></i><b>4.3</b> Idealized representations of distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#skewness"><i class="fa fa-check"></i><b>4.3.1</b> Skewness</a></li>
<li class="chapter" data-level="4.3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#long-tailed-distributions"><i class="fa fa-check"></i><b>4.3.2</b> Long-tailed distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="summarizing-data.html"><a href="summarizing-data.html#suggested-readings-3"><i class="fa fa-check"></i><b>4.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html"><i class="fa fa-check"></i><b>5</b> Fitting models to data</a><ul>
<li class="chapter" data-level="5.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#what-is-a-model"><i class="fa fa-check"></i><b>5.1</b> What is a model?</a></li>
<li class="chapter" data-level="5.2" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#statistical-modeling-an-example"><i class="fa fa-check"></i><b>5.2</b> Statistical modeling: An example</a><ul>
<li class="chapter" data-level="5.2.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#improving-our-model"><i class="fa fa-check"></i><b>5.2.1</b> Improving our model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#what-makes-a-model-good"><i class="fa fa-check"></i><b>5.3</b> What makes a model “good”?</a></li>
<li class="chapter" data-level="5.4" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#overfitting"><i class="fa fa-check"></i><b>5.4</b> Can a model be too good?</a></li>
<li class="chapter" data-level="5.5" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-simplest-model-the-mean"><i class="fa fa-check"></i><b>5.5</b> The simplest model: The mean</a><ul>
<li class="chapter" data-level="5.5.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-median"><i class="fa fa-check"></i><b>5.5.1</b> The median</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-mode"><i class="fa fa-check"></i><b>5.6</b> The mode</a></li>
<li class="chapter" data-level="5.7" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#variability-how-well-does-the-mean-fit-the-data"><i class="fa fa-check"></i><b>5.7</b> Variability: How well does the mean fit the data?</a></li>
<li class="chapter" data-level="5.8" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#using-simulations-to-understand-statistics"><i class="fa fa-check"></i><b>5.8</b> Using simulations to understand statistics</a></li>
<li class="chapter" data-level="5.9" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#z-scores"><i class="fa fa-check"></i><b>5.9</b> Z-scores</a><ul>
<li class="chapter" data-level="5.9.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#interpreting-z-scores"><i class="fa fa-check"></i><b>5.9.1</b> Interpreting Z-scores</a></li>
<li class="chapter" data-level="5.9.2" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#standardized-scores"><i class="fa fa-check"></i><b>5.9.2</b> Standardized scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="data-visualization.html"><a href="data-visualization.html#how-data-visualization-can-save-lives"><i class="fa fa-check"></i><b>6.1</b> How data visualization can save lives</a></li>
<li class="chapter" data-level="6.2" data-path="data-visualization.html"><a href="data-visualization.html#anatomy-of-a-plot"><i class="fa fa-check"></i><b>6.2</b> Anatomy of a plot</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html"><i class="fa fa-check"></i><b>7</b> plot height by Gender</a><ul>
<li class="chapter" data-level="7.1" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#plotting-in-r-using-ggplot"><i class="fa fa-check"></i><b>7.1</b> Plotting in R using ggplot</a></li>
<li class="chapter" data-level="7.2" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#principles-of-good-visualization"><i class="fa fa-check"></i><b>7.2</b> Principles of good visualization</a><ul>
<li class="chapter" data-level="7.2.1" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#show-the-data-and-make-them-stand-out"><i class="fa fa-check"></i><b>7.2.1</b> Show the data and make them stand out</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#maximize-the-dataink-ratio"><i class="fa fa-check"></i><b>7.3</b> Maximize the data/ink ratio</a></li>
<li class="chapter" data-level="7.4" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#avoid-chartjunk"><i class="fa fa-check"></i><b>7.4</b> Avoid chartjunk</a></li>
<li class="chapter" data-level="7.5" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#avoid-distorting-the-data"><i class="fa fa-check"></i><b>7.5</b> Avoid distorting the data</a></li>
<li class="chapter" data-level="7.6" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#the-lie-factor"><i class="fa fa-check"></i><b>7.6</b> The lie factor</a></li>
<li class="chapter" data-level="7.7" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#remember-human-limitations"><i class="fa fa-check"></i><b>7.7</b> Remember human limitations</a><ul>
<li class="chapter" data-level="7.7.1" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#perceptual-limitations"><i class="fa fa-check"></i><b>7.7.1</b> Perceptual limitations</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#correcting-for-other-factors"><i class="fa fa-check"></i><b>7.8</b> Correcting for other factors</a></li>
<li class="chapter" data-level="7.9" data-path="plot-height-by-gender.html"><a href="plot-height-by-gender.html#suggested-readings-and-videos"><i class="fa fa-check"></i><b>7.9</b> Suggested readings and videos</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sampling-1.html"><a href="sampling-1.html"><i class="fa fa-check"></i><b>8</b> Sampling</a><ul>
<li class="chapter" data-level="8.1" data-path="sampling-1.html"><a href="sampling-1.html#how-do-we-sample"><i class="fa fa-check"></i><b>8.1</b> How do we sample?</a></li>
<li class="chapter" data-level="8.2" data-path="sampling-1.html"><a href="sampling-1.html#sampling-error"><i class="fa fa-check"></i><b>8.2</b> Sampling error</a></li>
<li class="chapter" data-level="8.3" data-path="sampling-1.html"><a href="sampling-1.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>8.3</b> Standard error of the mean</a></li>
<li class="chapter" data-level="8.4" data-path="sampling-1.html"><a href="sampling-1.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>8.4</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="8.5" data-path="sampling-1.html"><a href="sampling-1.html#confidence-intervals"><i class="fa fa-check"></i><b>8.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="8.6" data-path="sampling-1.html"><a href="sampling-1.html#suggested-readings-4"><i class="fa fa-check"></i><b>8.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html"><i class="fa fa-check"></i><b>9</b> Resampling and simulation</a><ul>
<li class="chapter" data-level="9.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>9.1</b> Monte Carlo simulation</a></li>
<li class="chapter" data-level="9.2" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#randomness-in-statistics"><i class="fa fa-check"></i><b>9.2</b> Randomness in statistics</a></li>
<li class="chapter" data-level="9.3" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#generating-random-numbers"><i class="fa fa-check"></i><b>9.3</b> Generating random numbers</a></li>
<li class="chapter" data-level="9.4" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-monte-carlo-simulation"><i class="fa fa-check"></i><b>9.4</b> Using Monte Carlo simulation</a></li>
<li class="chapter" data-level="9.5" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-simulation-for-statistics-the-bootstrap"><i class="fa fa-check"></i><b>9.5</b> Using simulation for statistics: The bootstrap</a><ul>
<li class="chapter" data-level="9.5.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#computing-the-bootstrap"><i class="fa fa-check"></i><b>9.5.1</b> Computing the bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#suggested-readings-5"><i class="fa fa-check"></i><b>9.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-nhst"><i class="fa fa-check"></i><b>10.1</b> Null Hypothesis Statistical Testing (NHST)</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-an-example"><i class="fa fa-check"></i><b>10.2</b> Null hypothesis statistical testing: An example</a></li>
<li class="chapter" data-level="10.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-process-of-null-hypothesis-testing"><i class="fa fa-check"></i><b>10.3</b> The process of null hypothesis testing</a><ul>
<li class="chapter" data-level="10.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-1-formulate-a-hypothesis"><i class="fa fa-check"></i><b>10.3.1</b> Step 1: Formulate a hypothesis</a></li>
<li class="chapter" data-level="10.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-2-collect-some-data"><i class="fa fa-check"></i><b>10.3.2</b> Step 2: Collect some data</a></li>
<li class="chapter" data-level="10.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-3-specify-the-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>10.3.3</b> Step 3: Specify the null and alternative hypotheses</a></li>
<li class="chapter" data-level="10.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-4-fit-a-model-to-the-data-and-compute-a-test-statistic"><i class="fa fa-check"></i><b>10.3.4</b> Step 4: Fit a model to the data and compute a test statistic</a></li>
<li class="chapter" data-level="10.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-5-determine-the-probability-of-the-data-under-the-null-hypothesis"><i class="fa fa-check"></i><b>10.3.5</b> Step 5: Determine the probability of the data under the null hypothesis</a></li>
<li class="chapter" data-level="10.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-6-assess-the-statistical-significance-of-the-result"><i class="fa fa-check"></i><b>10.3.6</b> Step 6: Assess the “statistical significance” of the result</a></li>
<li class="chapter" data-level="10.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#what-does-a-significant-result-mean"><i class="fa fa-check"></i><b>10.3.7</b> What does a significant result mean?</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#nhst-in-a-modern-context-multiple-testing"><i class="fa fa-check"></i><b>10.4</b> NHST in a modern context: Multiple testing</a></li>
<li class="chapter" data-level="10.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#suggested-readings-6"><i class="fa fa-check"></i><b>10.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html"><i class="fa fa-check"></i><b>11</b> Confidence intervals, effect sizes, and statistical power</a><ul>
<li class="chapter" data-level="11.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-1"><i class="fa fa-check"></i><b>11.1</b> Confidence intervals</a><ul>
<li class="chapter" data-level="11.1.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-normal-distribution"><i class="fa fa-check"></i><b>11.1.1</b> Confidence intervals using the normal distribution</a></li>
<li class="chapter" data-level="11.1.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-t-distribution"><i class="fa fa-check"></i><b>11.1.2</b> Confidence intervals using the t distribution</a></li>
<li class="chapter" data-level="11.1.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-and-sample-size"><i class="fa fa-check"></i><b>11.1.3</b> Confidence intervals and sample size</a></li>
<li class="chapter" data-level="11.1.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#computing-confidence-intervals-using-the-bootstrap"><i class="fa fa-check"></i><b>11.1.4</b> Computing confidence intervals using the bootstrap</a></li>
<li class="chapter" data-level="11.1.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#relation-of-confidence-intervals-to-hypothesis-tests"><i class="fa fa-check"></i><b>11.1.5</b> Relation of confidence intervals to hypothesis tests</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#effect-sizes"><i class="fa fa-check"></i><b>11.2</b> Effect sizes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#cohens-d"><i class="fa fa-check"></i><b>11.2.1</b> Cohen’s D</a></li>
<li class="chapter" data-level="11.2.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#pearsons-r"><i class="fa fa-check"></i><b>11.2.2</b> Pearson’s r</a></li>
<li class="chapter" data-level="11.2.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#odds-ratio"><i class="fa fa-check"></i><b>11.2.3</b> Odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#statistical-power"><i class="fa fa-check"></i><b>11.3</b> Statistical power</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#power-analysis"><i class="fa fa-check"></i><b>11.3.1</b> Power analysis</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#suggested-readings-7"><i class="fa fa-check"></i><b>11.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>12</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#generative-models"><i class="fa fa-check"></i><b>12.1</b> Generative models</a></li>
<li class="chapter" data-level="12.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-theorem-and-inverse-inference"><i class="fa fa-check"></i><b>12.2</b> Bayes’ theorem and inverse inference</a></li>
<li class="chapter" data-level="12.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#doing-bayesian-estimation"><i class="fa fa-check"></i><b>12.3</b> Doing Bayesian estimation</a><ul>
<li class="chapter" data-level="12.3.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior"><i class="fa fa-check"></i><b>12.3.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="12.3.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data"><i class="fa fa-check"></i><b>12.3.2</b> Collect some data</a></li>
<li class="chapter" data-level="12.3.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood"><i class="fa fa-check"></i><b>12.3.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="12.3.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood"><i class="fa fa-check"></i><b>12.3.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="12.3.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior"><i class="fa fa-check"></i><b>12.3.5</b> Computing the posterior</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#estimating-posterior-distributions"><i class="fa fa-check"></i><b>12.4</b> Estimating posterior distributions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior-1"><i class="fa fa-check"></i><b>12.4.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="12.4.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data-1"><i class="fa fa-check"></i><b>12.4.2</b> Collect some data</a></li>
<li class="chapter" data-level="12.4.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood-1"><i class="fa fa-check"></i><b>12.4.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="12.4.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood-1"><i class="fa fa-check"></i><b>12.4.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="12.4.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior-1"><i class="fa fa-check"></i><b>12.4.5</b> Computing the posterior</a></li>
<li class="chapter" data-level="12.4.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#maximum-a-posteriori-map-estimation"><i class="fa fa-check"></i><b>12.4.6</b> Maximum a posteriori (MAP) estimation</a></li>
<li class="chapter" data-level="12.4.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#credible-intervals"><i class="fa fa-check"></i><b>12.4.7</b> Credible intervals</a></li>
<li class="chapter" data-level="12.4.8" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#effects-of-different-priors"><i class="fa fa-check"></i><b>12.4.8</b> Effects of different priors</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#choosing-a-prior"><i class="fa fa-check"></i><b>12.5</b> Choosing a prior</a></li>
<li class="chapter" data-level="12.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>12.6</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="12.6.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-factors"><i class="fa fa-check"></i><b>12.6.1</b> Bayes factors</a></li>
<li class="chapter" data-level="12.6.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-factors-for-statistical-hypotheses"><i class="fa fa-check"></i><b>12.6.2</b> Bayes factors for statistical hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#suggested-readings-8"><i class="fa fa-check"></i><b>12.7</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html"><i class="fa fa-check"></i><b>13</b> Modeling categorical relationships</a><ul>
<li class="chapter" data-level="13.1" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#example-candy-colors"><i class="fa fa-check"></i><b>13.1</b> Example: Candy colors</a></li>
<li class="chapter" data-level="13.2" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#pearsons-chi-squared-test"><i class="fa fa-check"></i><b>13.2</b> Pearson’s chi-squared test</a></li>
<li class="chapter" data-level="13.3" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#contingency-tables-and-the-two-way-test"><i class="fa fa-check"></i><b>13.3</b> Contingency tables and the two-way test</a></li>
<li class="chapter" data-level="13.4" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#standardized-residuals"><i class="fa fa-check"></i><b>13.4</b> Standardized residuals</a></li>
<li class="chapter" data-level="13.5" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#odds-ratios"><i class="fa fa-check"></i><b>13.5</b> Odds ratios</a></li>
<li class="chapter" data-level="13.6" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#bayes-factor"><i class="fa fa-check"></i><b>13.6</b> Bayes factor</a></li>
<li class="chapter" data-level="13.7" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#categorical-analysis-beyond-the-2-x-2-table"><i class="fa fa-check"></i><b>13.7</b> Categorical analysis beyond the 2 X 2 table</a></li>
<li class="chapter" data-level="13.8" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#beware-of-simpsons-paradox"><i class="fa fa-check"></i><b>13.8</b> Beware of Simpson’s paradox</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html"><i class="fa fa-check"></i><b>14</b> Modeling continuous relationships</a><ul>
<li class="chapter" data-level="14.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#an-example-hate-crimes-and-income-inequality"><i class="fa fa-check"></i><b>14.1</b> An example: Hate crimes and income inequality</a><ul>
<li class="chapter" data-level="14.1.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#quantifying-inequality-the-gini-index"><i class="fa fa-check"></i><b>14.1.1</b> Quantifying inequality: The Gini index</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#is-income-inequality-related-to-hate-crimes"><i class="fa fa-check"></i><b>14.2</b> Is income inequality related to hate crimes?</a></li>
<li class="chapter" data-level="14.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#covariance-and-correlation"><i class="fa fa-check"></i><b>14.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="14.3.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#hypothesis-testing-for-correlations"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis testing for correlations</a></li>
<li class="chapter" data-level="14.3.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#robust-correlations"><i class="fa fa-check"></i><b>14.3.2</b> Robust correlations</a></li>
<li class="chapter" data-level="14.3.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#bayesian-correlation-analysis"><i class="fa fa-check"></i><b>14.3.3</b> Bayesian correlation analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#correlation-and-causation"><i class="fa fa-check"></i><b>14.4</b> Correlation and causation</a><ul>
<li class="chapter" data-level="14.4.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#causal-graphs"><i class="fa fa-check"></i><b>14.4.1</b> Causal graphs</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#suggested-readings-9"><i class="fa fa-check"></i><b>14.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html"><i class="fa fa-check"></i><b>15</b> The General Linear Model</a><ul>
<li class="chapter" data-level="15.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#linear-regression"><i class="fa fa-check"></i><b>15.1</b> Linear regression</a><ul>
<li class="chapter" data-level="15.1.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#regression-to-the-mean"><i class="fa fa-check"></i><b>15.1.1</b> Regression to the mean</a></li>
<li class="chapter" data-level="15.1.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#estimating-linear-regression-parameters"><i class="fa fa-check"></i><b>15.1.2</b> Estimating linear regression parameters</a></li>
<li class="chapter" data-level="15.1.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#the-relation-between-correlation-and-regression"><i class="fa fa-check"></i><b>15.1.3</b> The relation between correlation and regression</a></li>
<li class="chapter" data-level="15.1.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#standard-errors-for-regression-models"><i class="fa fa-check"></i><b>15.1.4</b> Standard errors for regression models</a></li>
<li class="chapter" data-level="15.1.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#statistical-tests-for-regression-parameters"><i class="fa fa-check"></i><b>15.1.5</b> Statistical tests for regression parameters</a></li>
<li class="chapter" data-level="15.1.6" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#quantifying-goodness-of-fit-of-the-model"><i class="fa fa-check"></i><b>15.1.6</b> Quantifying goodness of fit of the model</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#fitting-more-complex-models"><i class="fa fa-check"></i><b>15.2</b> Fitting more complex models</a></li>
<li class="chapter" data-level="15.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#interactions-between-variables"><i class="fa fa-check"></i><b>15.3</b> Interactions between variables</a></li>
<li class="chapter" data-level="15.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#what-does-predict-really-mean"><i class="fa fa-check"></i><b>15.4</b> What does “predict” really mean?</a><ul>
<li class="chapter" data-level="15.4.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#cross-validation"><i class="fa fa-check"></i><b>15.4.1</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#suggested-readings-10"><i class="fa fa-check"></i><b>15.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="comparing-means.html"><a href="comparing-means.html"><i class="fa fa-check"></i><b>16</b> Comparing means</a><ul>
<li class="chapter" data-level="16.1" data-path="comparing-means.html"><a href="comparing-means.html#students-t-test"><i class="fa fa-check"></i><b>16.1</b> Student’s T test</a></li>
<li class="chapter" data-level="16.2" data-path="comparing-means.html"><a href="comparing-means.html#the-t-test-as-a-linear-model"><i class="fa fa-check"></i><b>16.2</b> The t-test as a linear model</a><ul>
<li class="chapter" data-level="16.2.1" data-path="comparing-means.html"><a href="comparing-means.html#effect-sizes-for-comparing-two-means"><i class="fa fa-check"></i><b>16.2.1</b> Effect sizes for comparing two means</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="comparing-means.html"><a href="comparing-means.html#bayes-factor-for-mean-differences"><i class="fa fa-check"></i><b>16.3</b> Bayes factor for mean differences</a></li>
<li class="chapter" data-level="16.4" data-path="comparing-means.html"><a href="comparing-means.html#paired-t-tests"><i class="fa fa-check"></i><b>16.4</b> Paired t-tests</a><ul>
<li class="chapter" data-level="16.4.1" data-path="comparing-means.html"><a href="comparing-means.html#sign-test"><i class="fa fa-check"></i><b>16.4.1</b> Sign test</a></li>
<li class="chapter" data-level="16.4.2" data-path="comparing-means.html"><a href="comparing-means.html#paired-t-test"><i class="fa fa-check"></i><b>16.4.2</b> Paired t-test</a></li>
<li class="chapter" data-level="16.4.3" data-path="comparing-means.html"><a href="comparing-means.html#the-paired-t-test-as-a-linear-model"><i class="fa fa-check"></i><b>16.4.3</b> The paired t-test as a linear model</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="comparing-means.html"><a href="comparing-means.html#comparing-more-than-two-means"><i class="fa fa-check"></i><b>16.5</b> Comparing more than two means</a><ul>
<li class="chapter" data-level="16.5.1" data-path="comparing-means.html"><a href="comparing-means.html#analysis-of-variance"><i class="fa fa-check"></i><b>16.5.1</b> Analysis of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="practical-example.html"><a href="practical-example.html"><i class="fa fa-check"></i><b>17</b> The process of statistical modeling: A practical example</a><ul>
<li class="chapter" data-level="17.1" data-path="practical-example.html"><a href="practical-example.html#the-process-of-statistical-modeling"><i class="fa fa-check"></i><b>17.1</b> The process of statistical modeling</a><ul>
<li class="chapter" data-level="17.1.1" data-path="practical-example.html"><a href="practical-example.html#specify-your-question-of-interest"><i class="fa fa-check"></i><b>17.1.1</b> 1: Specify your question of interest</a></li>
<li class="chapter" data-level="17.1.2" data-path="practical-example.html"><a href="practical-example.html#identify-or-collect-the-appropriate-data"><i class="fa fa-check"></i><b>17.1.2</b> 2: Identify or collect the appropriate data</a></li>
<li class="chapter" data-level="17.1.3" data-path="practical-example.html"><a href="practical-example.html#prepare-the-data-for-analysis"><i class="fa fa-check"></i><b>17.1.3</b> 3: Prepare the data for analysis</a></li>
<li class="chapter" data-level="17.1.4" data-path="practical-example.html"><a href="practical-example.html#determine-the-appropriate-model"><i class="fa fa-check"></i><b>17.1.4</b> 4. Determine the appropriate model</a></li>
<li class="chapter" data-level="17.1.5" data-path="practical-example.html"><a href="practical-example.html#fit-the-model-to-the-data"><i class="fa fa-check"></i><b>17.1.5</b> 5. Fit the model to the data</a></li>
<li class="chapter" data-level="17.1.6" data-path="practical-example.html"><a href="practical-example.html#criticize-the-model-to-make-sure-it-fits-properly"><i class="fa fa-check"></i><b>17.1.6</b> 6. Criticize the model to make sure it fits properly</a></li>
<li class="chapter" data-level="17.1.7" data-path="practical-example.html"><a href="practical-example.html#test-hypothesis-and-quantify-effect-size"><i class="fa fa-check"></i><b>17.1.7</b> 7. Test hypothesis and quantify effect size</a></li>
<li class="chapter" data-level="17.1.8" data-path="practical-example.html"><a href="practical-example.html#what-about-possible-confounds"><i class="fa fa-check"></i><b>17.1.8</b> What about possible confounds?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html"><i class="fa fa-check"></i><b>18</b> Doing reproducible research</a><ul>
<li class="chapter" data-level="18.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-we-think-science-should-work"><i class="fa fa-check"></i><b>18.1</b> How we think science should work</a></li>
<li class="chapter" data-level="18.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-science-sometimes-actually-works"><i class="fa fa-check"></i><b>18.2</b> How science (sometimes) actually works</a></li>
<li class="chapter" data-level="18.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-reproducibility-crisis-in-science"><i class="fa fa-check"></i><b>18.3</b> The reproducibility crisis in science</a><ul>
<li class="chapter" data-level="18.3.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#positive-predictive-value-and-statistical-significance"><i class="fa fa-check"></i><b>18.3.1</b> Positive predictive value and statistical significance</a></li>
<li class="chapter" data-level="18.3.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-winners-curse"><i class="fa fa-check"></i><b>18.3.2</b> The winner’s curse</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#questionable-research-practices"><i class="fa fa-check"></i><b>18.4</b> Questionable research practices</a><ul>
<li class="chapter" data-level="18.4.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#esp-or-qrp"><i class="fa fa-check"></i><b>18.4.1</b> ESP or QRP?</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-research-1"><i class="fa fa-check"></i><b>18.5</b> Doing reproducible research</a><ul>
<li class="chapter" data-level="18.5.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#pre-registration"><i class="fa fa-check"></i><b>18.5.1</b> Pre-registration</a></li>
<li class="chapter" data-level="18.5.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#reproducible-practices"><i class="fa fa-check"></i><b>18.5.2</b> Reproducible practices</a></li>
<li class="chapter" data-level="18.5.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#replication"><i class="fa fa-check"></i><b>18.5.3</b> Replication</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-data-analysis"><i class="fa fa-check"></i><b>18.6</b> Doing reproducible data analysis</a></li>
<li class="chapter" data-level="18.7" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#conclusion-doing-better-science"><i class="fa fa-check"></i><b>18.7</b> Conclusion: Doing better science</a></li>
<li class="chapter" data-level="18.8" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#suggested-readings-11"><i class="fa fa-check"></i><b>18.8</b> Suggested Readings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Thinking for the 21st Century</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="comparing-means" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Comparing means</h1>
<p>One of the most common questions that we want to ask in statistics is whether there is a difference between the means of two different groups. Let’s say that we would like to know whether regular marijuana smokers watch more television. We can ask this question using the NHANES dataset; let’s take a sample of 200 individuals from the dataset and test whether the number of hours of television watching per day is related to regular marijuana use. Figure <a href="comparing-means.html#fig:PotTVViolin">16.1</a> shows these data using a violin plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create sample with tv watching and marijuana use</span>
NHANES_sample &lt;-
<span class="st">  </span>NHANES_adult <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(TVHrsDay, RegularMarij) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">TVHrsNum =</span> <span class="kw">recode</span>( <span class="co">#recode character values into numerical values</span>
      TVHrsDay,
      <span class="st">&quot;More_4_hr&quot;</span> =<span class="st"> </span><span class="dv">5</span>,
      <span class="st">&quot;4_hr&quot;</span> =<span class="st"> </span><span class="dv">4</span>, 
      <span class="st">&quot;2_hr&quot;</span> =<span class="st"> </span><span class="dv">2</span>,
      <span class="st">&quot;1_hr&quot;</span> =<span class="st"> </span><span class="dv">1</span>, 
      <span class="st">&quot;3_hr&quot;</span> =<span class="st"> </span><span class="dv">3</span>, 
      <span class="st">&quot;0_to_1_hr&quot;</span> =<span class="st"> </span><span class="fl">0.5</span>,
      <span class="st">&quot;0_hrs&quot;</span> =<span class="st"> </span><span class="dv">0</span>
    )
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">200</span>)</code></pre></div>
<div class="figure"><span id="fig:PotTVViolin"></span>
<img src="StatsThinking21_files/figure-html/PotTVViolin-1.png" alt="Violin plot showing distributions of TV watching separated by regular marijuana use." width="384" height="50%" />
<p class="caption">
Figure 16.1: Violin plot showing distributions of TV watching separated by regular marijuana use.
</p>
</div>
<div id="students-t-test" class="section level2">
<h2><span class="header-section-number">16.1</span> Student’s T test</h2>
<p>We have already encountered Student’s t statistic in the previous chapter on hypothesis testing. This statistic provides us with a way to test for differences between two groups of independent observations; we will turn later in the chapter to cases where the observations are not independent. As a reminder, the t-statistic for comparison of two independent groups is computed as:</p>
<p><span class="math display">\[
t = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}}}
\]</span></p>
<p>where <span class="math inline">\(\bar{X}_1\)</span> and <span class="math inline">\(\bar{X}_2\)</span> are the means of the two groups, <span class="math inline">\(S^2_1\)</span> and <span class="math inline">\(S^2_2\)</span> are the variances for each the groups, and <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are the sizes of the two groups. Under the null hypothesis of no difference between means, this statistic is distributed according to a t distribution with n-2 degrees of freedom (since we have computed two parameter estimates, namely the means of the two groups). We can compute the t-test in R using the <code>t.test()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute t test for tv watching as function of marijuana use</span>
<span class="kw">t.test</span>(
  TVHrsNum <span class="op">~</span><span class="st"> </span>RegularMarij,
  <span class="dt">data =</span> NHANES_sample,
  <span class="dt">var.equal =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  TVHrsNum by RegularMarij
## t = -3, df = 200, p-value = 0.003
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.07 -0.22
## sample estimates:
##  mean in group No mean in group Yes 
##               2.2               2.8</code></pre>
<p>In this case we see that there is a statstically significant difference between groups, in the expected direction - regular pot smokers watch more TV.</p>
</div>
<div id="the-t-test-as-a-linear-model" class="section level2">
<h2><span class="header-section-number">16.2</span> The t-test as a linear model</h2>
<p>The t-test is often presented as a specialized tool for comparing means, but it can also be viewed as an application of the general linear model. In this case, the model would look like this:</p>
<p><span class="math display">\[
\hat{BP} = \hat{\beta_1}*Smoking + \hat{\beta_0}
\]</span> However, smoking is a binary variable, so we treat it as a <em>dummy variable</em> like we discussed in the previous chapter, setting it to a value of 1 for smokers and zero for nonsmokers. In that case, <span class="math inline">\(\hat{\beta_1}\)</span> is simply the difference in means between the two groups, and <span class="math inline">\(\hat{\beta_0}\)</span> is the mean for the group that was coded as zero. We can fit this model using the <code>lm()</code> function, and see that it gives the same t statistic as the t-test above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># print summary of linear regression to perform t-test</span>
s &lt;-<span class="st"> </span><span class="kw">summary</span>(<span class="kw">lm</span>(TVHrsNum <span class="op">~</span><span class="st"> </span>RegularMarij, <span class="dt">data =</span> NHANES_sample))
s</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = TVHrsNum ~ RegularMarij, data = NHANES_sample)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.810 -1.165 -0.166  0.835  2.834 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        2.165      0.115   18.86   &lt;2e-16 ***
## RegularMarijYes    0.645      0.213    3.02   0.0028 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.4 on 198 degrees of freedom
## Multiple R-squared:  0.0441, Adjusted R-squared:  0.0393 
## F-statistic: 9.14 on 1 and 198 DF,  p-value: 0.00282</code></pre>
<p>We can also view this graphically (see Figure :</p>
<div class="figure"><span id="fig:ttestFig"></span>
<img src="StatsThinking21_files/figure-html/ttestFig-1.png" alt="Violin plots showing data for each group, with a blue line connecting the predicted values for each group, computed on the basis of the results of the linear model." width="384" height="50%" />
<p class="caption">
Figure 16.2: Violin plots showing data for each group, with a blue line connecting the predicted values for each group, computed on the basis of the results of the linear model.
</p>
</div>
<p>In this case, the predicted value for nonsmokers is <span class="math inline">\(\hat{\beta_0}\)</span> (2.17) and the predicted value for smokers is <span class="math inline">\(\hat{\beta_0} +\hat{\beta_1}\)</span> (2.81).</p>
<p>To compute the standard errors for this analysis, we can use exactly the same equations that we used for linear regression – since this really is just another example of linear regression. In fact, if you compare the p-value from the t-test above with the p-value in the linear regression analysis for the marijuana use variable, you will see that they are exactly the same.</p>
<div id="effect-sizes-for-comparing-two-means" class="section level3">
<h3><span class="header-section-number">16.2.1</span> Effect sizes for comparing two means</h3>
<p>The most commonly used effect size for a comparison between two means is Cohen’s d, which (as you may remember from Chapter <a href="ci-effect-size-power.html#ci-effect-size-power">11</a>) is an expression of the effect in terms of standard error units. For the t-test estimated using the general linear model outlined above, this is expressed as:</p>
<p><span class="math display">\[
d = \frac{\hat{beta_1}}{SE_{residual}}
\]</span> We can obtain these values from the analysis output above, giving us a d = 0.47, which we would generally interpret as a medium sized effect.</p>
<p>We can also compute <span class="math inline">\(R^2\)</span> for this analysis, which tells us how much variance in TV watching is accounted for. This value (which is reported in the summary of the lm() analysis) is 0.04, which tells us that while the effect may be statistically significant, it accounts for relatively little of the variance in TV watching.</p>
</div>
</div>
<div id="bayes-factor-for-mean-differences" class="section level2">
<h2><span class="header-section-number">16.3</span> Bayes factor for mean differences</h2>
<p>As we discussed in the chapter on Bayesian analysis, Bayes factors provide a way to better quantify evidence in favor or against the null hypothesis of no difference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute bayes factor for group comparison</span>
bf &lt;-<span class="st"> </span><span class="kw">ttestBF</span>(
  <span class="dt">formula =</span> TVHrsNum <span class="op">~</span><span class="st"> </span>RegularMarij, 
  <span class="dt">data =</span> NHANES_sample
)
bf</code></pre></div>
<pre><code>## Bayes factor analysis
## --------------
## [1] Alt., r=0.707 : 11 ±0%
## 
## Against denominator:
##   Null, mu1-mu2 = 0 
## ---
## Bayes factor type: BFindepSample, JZS</code></pre>
<p>This shows us that although the difference between groups is highly significant, the evidence against the null hypothesis is suggestive but not particularly strong.</p>
</div>
<div id="paired-t-tests" class="section level2">
<h2><span class="header-section-number">16.4</span> Paired t-tests</h2>
<p>In experimental research, we often use <em>within-subjects</em> designs, in which we compare the same person on multiple measurements. For example, in the NHANES dataset blood pressure was measured three times. Let’s say that we are interested in testing whether there is a difference in mean blood pressure between the first and second measurement (Figure <a href="comparing-means.html#fig:BPfig">16.3</a>).</p>
<div class="figure"><span id="fig:BPfig"></span>
<img src="StatsThinking21_files/figure-html/BPfig-1.png" alt="Violin plot of systolic blood pressure on first and second recording, from NHANES." width="384" height="50%" />
<p class="caption">
Figure 16.3: Violin plot of systolic blood pressure on first and second recording, from NHANES.
</p>
</div>
<p>We see that there does not seem to be much of a difference in mean blood pressure between time points (about one point). First let’s test for a difference using an independent samples t-test, which ignores the fact that pairs of data points come from the the same individuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(
  BPsys <span class="op">~</span><span class="st"> </span>timepoint,
  <span class="dt">data =</span> NHANES_sample_tidy,
  <span class="dt">paired =</span> <span class="ot">FALSE</span>, 
  <span class="dt">var.equal =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  BPsys by timepoint
## t = 0.5, df = 400, p-value = 0.6
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.8  4.6
## sample estimates:
## mean in group BPSys1 mean in group BPSys2 
##                  122                  121</code></pre>
<p>This analysis shows no significant difference. However, this analysis is inappropriate since it assumes that the two samples are independent, when in fact they are not, since the data come from the same individuals. We can plot the data with a line for each individual to show this (see Figure <a href="comparing-means.html#fig:BPLinePlot">16.4</a>).</p>
<div class="figure"><span id="fig:BPLinePlot"></span>
<img src="StatsThinking21_files/figure-html/BPLinePlot-1.png" alt="Violin plot of systolic BP on each recording, with lines connecting the two data points for each individual." width="384" height="50%" />
<p class="caption">
Figure 16.4: Violin plot of systolic BP on each recording, with lines connecting the two data points for each individual.
</p>
</div>
<p>In this analysis, what we really care about is whether the blood pressure for each person changed in a systematic way between the two measurements, so another way to represent the data is to compute the difference between the two timepoints for each individual, and then analyze these difference scores rather than analyzing the individual measurements. In Figure <a href="comparing-means.html#fig:BPDiffHist">16.5</a>, we show a histogram of these difference scores, with a blue line denoting the mean difference.</p>
<div class="figure"><span id="fig:BPDiffHist"></span>
<img src="StatsThinking21_files/figure-html/BPDiffHist-1.png" alt="Histogram of difference scores between first and second BP measurement." width="384" height="50%" />
<p class="caption">
Figure 16.5: Histogram of difference scores between first and second BP measurement.
</p>
</div>
<div id="sign-test" class="section level3">
<h3><span class="header-section-number">16.4.1</span> Sign test</h3>
<p>One simple way to test for differences is using a test called the <em>sign test</em>, which asks whether the proportion of positive differences (ignoring their magnitude) is different than what we would expect by chance. To do this, we take the differences and compute their sign, and then we use a binomial test to ask whether the proportion of positive signs differs from 0.5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute sign test for differences between first and second measurement</span>
npos &lt;-<span class="st"> </span><span class="kw">sum</span>(NHANES_sample<span class="op">$</span>diffPos)
bt &lt;-<span class="st"> </span><span class="kw">binom.test</span>(npos, <span class="kw">nrow</span>(NHANES_sample))
bt</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  npos and nrow(NHANES_sample)
## number of successes = 100, number of trials = 200, p-value = 0.4
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.46 0.60
## sample estimates:
## probability of success 
##                   0.53</code></pre>
<p>Here we see that the proportion of individuals with positive signs (0.53) is not large enough to be surprising under the null hypothesis of <span class="math inline">\(p=0.5\)</span>. However, one problem with the sign test is that it is throwing away information about the magnitude of the differences, and thus might be missing something.</p>
</div>
<div id="paired-t-test" class="section level3">
<h3><span class="header-section-number">16.4.2</span> Paired t-test</h3>
<p>A more common strategy is to use a <em>paired t-test</em>, which is equivalent to a one-sample t-test for whether the mean difference between the measurements is zero. We can compute this using the <code>t.test()</code> function in R and setting <code>paired=TRUE</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute paired t-test</span>
<span class="kw">t.test</span>(BPsys <span class="op">~</span><span class="st"> </span>timepoint, <span class="dt">data =</span> NHANES_sample_tidy, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  BPsys by timepoint
## t = 2, df = 200, p-value = 0.02
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.17 1.69
## sample estimates:
## mean of the differences 
##                    0.93</code></pre>
<p>With this analyses we see that there is in fact a significant difference between the two measurements. Let’s compute the Bayes factor to see how strong this effect is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute Bayes factor for paired t-test</span>
<span class="kw">ttestBF</span>(<span class="dt">x =</span> NHANES_sample<span class="op">$</span>BPSys1, <span class="dt">y =</span> NHANES_sample<span class="op">$</span>BPSys2, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Bayes factor analysis
## --------------
## [1] Alt., r=0.707 : 1.3 ±0%
## 
## Against denominator:
##   Null, mu = 0 
## ---
## Bayes factor type: BFoneSample, JZS</code></pre>
<p>This shows us that although the effect was significant in a paired t-test, it actually provides very little evidence in favor of the alternative hypothesis.</p>
</div>
<div id="the-paired-t-test-as-a-linear-model" class="section level3">
<h3><span class="header-section-number">16.4.3</span> The paired t-test as a linear model</h3>
<p>We can also define the paired t-test in terms of a general linear model. To do this, we include all of the measurements for each subject as data points (within a tidy data frame). We then include in the model a variable that codes for the identity of each individual (in this case, the ID variable that contains a subject ID for each person). This is known as a <em>mixed model</em>, since it includes effects of independent variables as well as effects of individuals. The standard model fitting procedure <code>lm()</code> can’t do this, but we can do it using the <code>lmer()</code> function from a popular R package called <em>lme4</em>, which is specialized for estimating mixed models. The <code>(1|ID)</code> in the formula tells <code>lmer()</code> to estimate a separate intercept (which is what the <code>1</code> refers to) for each value of the <code>ID</code> variable (i.e. for each individual in the dataset), and then estimate a common slope relating timepoint to BP.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute mixed model for paired test</span>

lmrResult &lt;-<span class="st"> </span><span class="kw">lmer</span>(BPsys <span class="op">~</span><span class="st"> </span>timepoint <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>ID), <span class="dt">data =</span> NHANES_sample_tidy)
<span class="kw">summary</span>(lmrResult)</code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: BPsys ~ timepoint + (1 | ID)
##    Data: NHANES_sample_tidy
## 
## REML criterion at convergence: 2982
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.6985 -0.4478  0.0058  0.3996  2.7395 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  ID       (Intercept) 342      18.49   
##  Residual              15       3.87   
## Number of obs: 400, groups:  ID, 200
## 
## Fixed effects:
##                 Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)      121.770      1.336 207.545    91.2   &lt;2e-16 ***
## timepointBPSys2   -0.930      0.387 199.000    -2.4    0.017 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr)
## tmpntBPSys2 -0.145</code></pre>
<p>You can see that this shows us a p-value that is very close to the result from the paired t-test computed using the <code>t.test()</code> function.</p>
</div>
</div>
<div id="comparing-more-than-two-means" class="section level2">
<h2><span class="header-section-number">16.5</span> Comparing more than two means</h2>
<p>Often we want to compare more than two means to determine whether any of them differ from one another. Let’s say that we are analyzing data from a clinical trial for the treatment of high blood pressure. In the study, volunteers are randomized to one of three conditions: Drug 1, Drug 2 or placebo. Let’s generate some data and plot them (see Figure <a href="comparing-means.html#fig:DrugTrial">16.6</a>)</p>
<div class="figure"><span id="fig:DrugTrial"></span>
<img src="StatsThinking21_files/figure-html/DrugTrial-1.png" alt="Box plots showing blood pressure for three different groups in our clinical trial." width="576" height="50%" />
<p class="caption">
Figure 16.6: Box plots showing blood pressure for three different groups in our clinical trial.
</p>
</div>
<div id="analysis-of-variance" class="section level3">
<h3><span class="header-section-number">16.5.1</span> Analysis of variance</h3>
<p>We would first like to test the null hypothesis that the means of all of the groups are equal – that is, neither of the treatments had any effect. We can do this using a method called <em>analysis of variance</em> (ANOVA). This is one of the most commonly used methods in psychological statistics, and we will only scratch the surface here. The basic idea behind ANOVA is one that we already discussed in the chapter on the general linear model, and in fact ANOVA is just a name for a specific implementation of such a model.</p>
<p>Remember from the last chapter that we can partition the total variance in the data (<span class="math inline">\(SS_{total}\)</span>) into the variance that is explained by the model (<span class="math inline">\(SS_{model}\)</span>) and the variance that is not (<span class="math inline">\(SS_{error}\)</span>). We can them compute a <em>mean square</em> for each of these by dividing them by their degrees of freedom; for the error this is <span class="math inline">\(N - p\)</span> (where <span class="math inline">\(p\)</span> is the number of means that we have computed), and for the model this is <span class="math inline">\(p - 1\)</span>:</p>
<p><span class="math display">\[
MS_{model} =\frac{SS_{model}}{df_{model}}= \frac{SS_{model}}{p-1}
\]</span></p>
<p><span class="math display">\[
MS_{error} = \frac{SS_{error}}{df_{error}} = \frac{SS_{error}}{N - p}
\]</span></p>
<p>With ANOVA, we want to test whether the variance accounted for by the model is greater than what we would expect by chance, under the null hypothesis of no differences between means. Whereas for the t distribution the expected value is zero under the null hypothesis, that’s not the case here, since sums of squares are always positive numbers. Fortunately, there is another standard distribution that describes how ratios of sums of squares are distributed under the null hypothesis: The <em>F</em> disribution (see figure <a href="comparing-means.html#fig:FDist">16.7</a>). This distribution has two degrees of freedom, which correspond to the degrees of freedom for the numerator (which in this case is the model), and the denominator (which in this case is the error).</p>
<div class="figure"><span id="fig:FDist"></span>
<img src="StatsThinking21_files/figure-html/FDist-1.png" alt="F distributions under the null hypothesis, for different values of degrees of freedom." width="576" height="50%" />
<p class="caption">
Figure 16.7: F distributions under the null hypothesis, for different values of degrees of freedom.
</p>
</div>
<p>To create an ANOVA model, we extend the idea of <em>dummy coding</em> that you encountered in the last chapter. Remember that for the t-test comparing two means, we created a single dummy variable that took the value of 1 for one of the conditions and zero for the others. Here we extend that idea by creating two dummy variables, one that codes for the Drug 1 condition and the other that codes for the Drug 2 condition. Just as in the t-test, we will have one condition (in this case, placebo) that doesn’t have a dummy variable, and thus represents the baseline against which the others are compared; its mean defines the intercept of the model. Let’s create the dummy coding for drugs 1 and 2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create dummy variables for drug1 and drug2</span>
df &lt;-
<span class="st">  </span>df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">d1 =</span> <span class="kw">as.integer</span>(group <span class="op">==</span><span class="st"> &quot;drug1&quot;</span>), <span class="co"># 1s for drug1, 0s for all other drugs</span>
    <span class="dt">d2 =</span> <span class="kw">as.integer</span>(group <span class="op">==</span><span class="st"> &quot;drug2&quot;</span>)  <span class="co"># 1s for drug2, 0s for all other drugs</span>
  )</code></pre></div>
<p>Now we can fit a model using the same approach that we used in the previous chapter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit ANOVA model</span>
lmResultANOVA &lt;-<span class="st"> </span><span class="kw">lm</span>(sysBP <span class="op">~</span><span class="st"> </span>d1 <span class="op">+</span><span class="st"> </span>d2, <span class="dt">data =</span> df)
<span class="kw">summary</span>(lmResultANOVA)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sysBP ~ d1 + d2, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.084  -7.745  -0.098   7.687  23.431 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   141.60       1.66   85.50  &lt; 2e-16 ***
## d1            -10.24       2.34   -4.37  2.9e-05 ***
## d2             -2.03       2.34   -0.87     0.39    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.9 on 105 degrees of freedom
## Multiple R-squared:  0.169,  Adjusted R-squared:  0.154 
## F-statistic: 10.7 on 2 and 105 DF,  p-value: 5.83e-05</code></pre>
<p>The output from this command provides us with two things. First, it shows us the result of a t-test for each of the dummy variables, which basically tell us whether each of the conditions separately differs from placebo; it appears that Drug 1 does whereas Drug 2 does not. However, keep in mind that if we wanted to interpret these tests, we would need to correct the p-values to account for the fact that we have done multiple hypothesis tests; we will see an example of how to do this in the next chapter.</p>
<p>Remember that the hypothesis that we started out wanting to test was whether there was any difference between any of the conditions; we refer to this as an <em>omnibus</em> hypothesis test, and it is the test that is provided by the F statistic. The F statistic basically tells us whether our model is better than a simple model that just includes an intercept. In this case we see that the F test is highly significant, consistent with our impression that there did seem to be differences between the groups (which in fact we know there were, because we created the data).</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-general-linear-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="practical-example.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/poldrack/psych10-book/edit/master/15-ComparingMeans.Rmd",
"text": "Edit"
},
"download": ["StatsThinking21.pdf", "StatsThinking21.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
