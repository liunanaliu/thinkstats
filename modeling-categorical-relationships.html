<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Thinking for the 21st Century</title>
  <meta name="description" content="Statistical Thinking for the 21st Century">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Thinking for the 21st Century" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="poldrack/psych10-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Thinking for the 21st Century" />
  
  
  

<meta name="author" content="Copyright 2018 Russell A. Poldrack">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bayesian-statistics.html">
<link rel="next" href="modeling-continuous-relationships.html">
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="book_assets/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="book_assets/viz-0.3/viz.js"></script>
<link href="book_assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="book_assets/grViz-binding-1.0.0/grViz.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129414074-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129414074-1');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#why-does-this-book-exist"><i class="fa fa-check"></i><b>0.1</b> Why does this book exist?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#youre-not-a-statistician---why-should-we-listen-to-you"><i class="fa fa-check"></i><b>0.2</b> You’re not a statistician - why should we listen to you?</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#why-r"><i class="fa fa-check"></i><b>0.3</b> Why R?</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#the-golden-age-of-data"><i class="fa fa-check"></i><b>0.4</b> The golden age of data</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#an-open-source-book"><i class="fa fa-check"></i><b>0.5</b> An open source book</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-statistical-thinking"><i class="fa fa-check"></i><b>1.1</b> What is statistical thinking?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-can-statistics-do-for-us"><i class="fa fa-check"></i><b>1.2</b> What can statistics do for us?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#fundamental-concepts-of-statistics"><i class="fa fa-check"></i><b>1.3</b> Fundamental concepts of statistics</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#learning-from-data"><i class="fa fa-check"></i><b>1.3.1</b> Learning from data</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#aggregation"><i class="fa fa-check"></i><b>1.3.2</b> Aggregation</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#uncertainty"><i class="fa fa-check"></i><b>1.3.3</b> Uncertainty</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#sampling"><i class="fa fa-check"></i><b>1.3.4</b> Sampling</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#causality-and-statistics"><i class="fa fa-check"></i><b>1.4</b> Causality and statistics</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#suggested-readings"><i class="fa fa-check"></i><b>1.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="working-with-data.html"><a href="working-with-data.html"><i class="fa fa-check"></i><b>2</b> Working with data</a><ul>
<li class="chapter" data-level="2.1" data-path="working-with-data.html"><a href="working-with-data.html#what-are-data"><i class="fa fa-check"></i><b>2.1</b> What are data?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="working-with-data.html"><a href="working-with-data.html#qualitative-data"><i class="fa fa-check"></i><b>2.1.1</b> Qualitative data</a></li>
<li class="chapter" data-level="2.1.2" data-path="working-with-data.html"><a href="working-with-data.html#quantitative-data"><i class="fa fa-check"></i><b>2.1.2</b> Quantitative data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="working-with-data.html"><a href="working-with-data.html#scales-of-measurement"><i class="fa fa-check"></i><b>2.2</b> Scales of measurement</a><ul>
<li class="chapter" data-level="2.2.1" data-path="working-with-data.html"><a href="working-with-data.html#why-do-scales-of-measurement-matter"><i class="fa fa-check"></i><b>2.2.1</b> Why do scales of measurement matter?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="working-with-data.html"><a href="working-with-data.html#what-makes-a-good-measurement"><i class="fa fa-check"></i><b>2.3</b> What makes a good measurement?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="working-with-data.html"><a href="working-with-data.html#reliability"><i class="fa fa-check"></i><b>2.3.1</b> <em>Reliability</em></a></li>
<li class="chapter" data-level="2.3.2" data-path="working-with-data.html"><a href="working-with-data.html#validity"><i class="fa fa-check"></i><b>2.3.2</b> <em>Validity</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="working-with-data.html"><a href="working-with-data.html#suggested-readings-1"><i class="fa fa-check"></i><b>2.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#what-is-probability"><i class="fa fa-check"></i><b>3.1</b> What is probability?</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#how-do-we-determine-probabilities"><i class="fa fa-check"></i><b>3.2</b> How do we determine probabilities?</a><ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#personal-opinion"><i class="fa fa-check"></i><b>3.2.1</b> Personal opinion</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#empirical-frequency"><i class="fa fa-check"></i><b>3.2.2</b> Empirical frequency</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2.3</b> Classical probability</a></li>
<li class="chapter" data-level="3.2.4" data-path="probability.html"><a href="probability.html#solving-de-meres-problem"><i class="fa fa-check"></i><b>3.2.4</b> Solving de Méré’s problem</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>3.3</b> Probability distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="probability.html"><a href="probability.html#cumulative-probability-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Cumulative probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.4</b> Conditional probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#computing-conditional-probabilities-from-data"><i class="fa fa-check"></i><b>3.5</b> Computing conditional probabilities from data</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>3.6</b> Independence</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#bayestheorem"><i class="fa fa-check"></i><b>3.7</b> Reversing a conditional probability: Bayes’ rule</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#learning-from-data-1"><i class="fa fa-check"></i><b>3.8</b> Learning from data</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#odds-and-odds-ratios"><i class="fa fa-check"></i><b>3.9</b> Odds and odds ratios</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#what-do-probabilities-mean"><i class="fa fa-check"></i><b>3.10</b> What do probabilities mean?</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#suggested-readings-2"><i class="fa fa-check"></i><b>3.11</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>4</b> Summarizing data</a><ul>
<li class="chapter" data-level="4.1" data-path="summarizing-data.html"><a href="summarizing-data.html#why-summarize-data"><i class="fa fa-check"></i><b>4.1</b> Why summarize data?</a></li>
<li class="chapter" data-level="4.2" data-path="summarizing-data.html"><a href="summarizing-data.html#summarizing-data-using-tables"><i class="fa fa-check"></i><b>4.2</b> Summarizing data using tables</a><ul>
<li class="chapter" data-level="4.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#frequency-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Frequency distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#cumulative-distributions"><i class="fa fa-check"></i><b>4.2.2</b> Cumulative distributions</a></li>
<li class="chapter" data-level="4.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#plotting-histograms"><i class="fa fa-check"></i><b>4.2.3</b> Plotting histograms</a></li>
<li class="chapter" data-level="4.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#histogram-bins"><i class="fa fa-check"></i><b>4.2.4</b> Histogram bins</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="summarizing-data.html"><a href="summarizing-data.html#idealized-representations-of-distributions"><i class="fa fa-check"></i><b>4.3</b> Idealized representations of distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#skewness"><i class="fa fa-check"></i><b>4.3.1</b> Skewness</a></li>
<li class="chapter" data-level="4.3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#long-tailed-distributions"><i class="fa fa-check"></i><b>4.3.2</b> Long-tailed distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="summarizing-data.html"><a href="summarizing-data.html#suggested-readings-3"><i class="fa fa-check"></i><b>4.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html"><i class="fa fa-check"></i><b>5</b> Fitting models to data</a><ul>
<li class="chapter" data-level="5.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#what-is-a-model"><i class="fa fa-check"></i><b>5.1</b> What is a model?</a></li>
<li class="chapter" data-level="5.2" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#statistical-modeling-an-example"><i class="fa fa-check"></i><b>5.2</b> Statistical modeling: An example</a><ul>
<li class="chapter" data-level="5.2.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#improving-our-model"><i class="fa fa-check"></i><b>5.2.1</b> Improving our model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#what-makes-a-model-good"><i class="fa fa-check"></i><b>5.3</b> What makes a model “good”?</a></li>
<li class="chapter" data-level="5.4" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#overfitting"><i class="fa fa-check"></i><b>5.4</b> Can a model be too good?</a></li>
<li class="chapter" data-level="5.5" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-simplest-model-the-mean"><i class="fa fa-check"></i><b>5.5</b> The simplest model: The mean</a><ul>
<li class="chapter" data-level="5.5.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-median"><i class="fa fa-check"></i><b>5.5.1</b> The median</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#the-mode"><i class="fa fa-check"></i><b>5.6</b> The mode</a></li>
<li class="chapter" data-level="5.7" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#variability-how-well-does-the-mean-fit-the-data"><i class="fa fa-check"></i><b>5.7</b> Variability: How well does the mean fit the data?</a></li>
<li class="chapter" data-level="5.8" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#using-simulations-to-understand-statistics"><i class="fa fa-check"></i><b>5.8</b> Using simulations to understand statistics</a></li>
<li class="chapter" data-level="5.9" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#z-scores"><i class="fa fa-check"></i><b>5.9</b> Z-scores</a><ul>
<li class="chapter" data-level="5.9.1" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#interpreting-z-scores"><i class="fa fa-check"></i><b>5.9.1</b> Interpreting Z-scores</a></li>
<li class="chapter" data-level="5.9.2" data-path="fitting-models-to-data.html"><a href="fitting-models-to-data.html#standardized-scores"><i class="fa fa-check"></i><b>5.9.2</b> Standardized scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="data-visualization.html"><a href="data-visualization.html#how-data-visualization-can-save-lives"><i class="fa fa-check"></i><b>6.1</b> How data visualization can save lives</a></li>
<li class="chapter" data-level="6.2" data-path="data-visualization.html"><a href="data-visualization.html#anatomy-of-a-plot"><i class="fa fa-check"></i><b>6.2</b> Anatomy of a plot</a></li>
<li class="chapter" data-level="6.3" data-path="data-visualization.html"><a href="data-visualization.html#plotting-in-r-using-ggplot"><i class="fa fa-check"></i><b>6.3</b> Plotting in R using ggplot</a></li>
<li class="chapter" data-level="6.4" data-path="data-visualization.html"><a href="data-visualization.html#principles-of-good-visualization"><i class="fa fa-check"></i><b>6.4</b> Principles of good visualization</a><ul>
<li class="chapter" data-level="6.4.1" data-path="data-visualization.html"><a href="data-visualization.html#show-the-data-and-make-them-stand-out"><i class="fa fa-check"></i><b>6.4.1</b> Show the data and make them stand out</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="data-visualization.html"><a href="data-visualization.html#maximize-the-dataink-ratio"><i class="fa fa-check"></i><b>6.5</b> Maximize the data/ink ratio</a></li>
<li class="chapter" data-level="6.6" data-path="data-visualization.html"><a href="data-visualization.html#avoid-chartjunk"><i class="fa fa-check"></i><b>6.6</b> Avoid chartjunk</a></li>
<li class="chapter" data-level="6.7" data-path="data-visualization.html"><a href="data-visualization.html#avoid-distorting-the-data"><i class="fa fa-check"></i><b>6.7</b> Avoid distorting the data</a></li>
<li class="chapter" data-level="6.8" data-path="data-visualization.html"><a href="data-visualization.html#the-lie-factor"><i class="fa fa-check"></i><b>6.8</b> The lie factor</a></li>
<li class="chapter" data-level="6.9" data-path="data-visualization.html"><a href="data-visualization.html#remember-human-limitations"><i class="fa fa-check"></i><b>6.9</b> Remember human limitations</a><ul>
<li class="chapter" data-level="6.9.1" data-path="data-visualization.html"><a href="data-visualization.html#perceptual-limitations"><i class="fa fa-check"></i><b>6.9.1</b> Perceptual limitations</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="data-visualization.html"><a href="data-visualization.html#correcting-for-other-factors"><i class="fa fa-check"></i><b>6.10</b> Correcting for other factors</a></li>
<li class="chapter" data-level="6.11" data-path="data-visualization.html"><a href="data-visualization.html#suggested-readings-and-videos"><i class="fa fa-check"></i><b>6.11</b> Suggested readings and videos</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling-1.html"><a href="sampling-1.html"><i class="fa fa-check"></i><b>7</b> Sampling</a><ul>
<li class="chapter" data-level="7.1" data-path="sampling-1.html"><a href="sampling-1.html#how-do-we-sample"><i class="fa fa-check"></i><b>7.1</b> How do we sample?</a></li>
<li class="chapter" data-level="7.2" data-path="sampling-1.html"><a href="sampling-1.html#sampling-error"><i class="fa fa-check"></i><b>7.2</b> Sampling error</a></li>
<li class="chapter" data-level="7.3" data-path="sampling-1.html"><a href="sampling-1.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>7.3</b> Standard error of the mean</a></li>
<li class="chapter" data-level="7.4" data-path="sampling-1.html"><a href="sampling-1.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>7.4</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="7.5" data-path="sampling-1.html"><a href="sampling-1.html#confidence-intervals"><i class="fa fa-check"></i><b>7.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="7.6" data-path="sampling-1.html"><a href="sampling-1.html#suggested-readings-4"><i class="fa fa-check"></i><b>7.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html"><i class="fa fa-check"></i><b>8</b> Resampling and simulation</a><ul>
<li class="chapter" data-level="8.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.1</b> Monte Carlo simulation</a></li>
<li class="chapter" data-level="8.2" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#randomness-in-statistics"><i class="fa fa-check"></i><b>8.2</b> Randomness in statistics</a></li>
<li class="chapter" data-level="8.3" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#generating-random-numbers"><i class="fa fa-check"></i><b>8.3</b> Generating random numbers</a></li>
<li class="chapter" data-level="8.4" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-monte-carlo-simulation"><i class="fa fa-check"></i><b>8.4</b> Using Monte Carlo simulation</a></li>
<li class="chapter" data-level="8.5" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-simulation-for-statistics-the-bootstrap"><i class="fa fa-check"></i><b>8.5</b> Using simulation for statistics: The bootstrap</a><ul>
<li class="chapter" data-level="8.5.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#computing-the-bootstrap"><i class="fa fa-check"></i><b>8.5.1</b> Computing the bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#suggested-readings-5"><i class="fa fa-check"></i><b>8.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>9</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="9.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-nhst"><i class="fa fa-check"></i><b>9.1</b> Null Hypothesis Statistical Testing (NHST)</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-an-example"><i class="fa fa-check"></i><b>9.2</b> Null hypothesis statistical testing: An example</a></li>
<li class="chapter" data-level="9.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-process-of-null-hypothesis-testing"><i class="fa fa-check"></i><b>9.3</b> The process of null hypothesis testing</a><ul>
<li class="chapter" data-level="9.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-1-formulate-a-hypothesis"><i class="fa fa-check"></i><b>9.3.1</b> Step 1: Formulate a hypothesis</a></li>
<li class="chapter" data-level="9.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-2-collect-some-data"><i class="fa fa-check"></i><b>9.3.2</b> Step 2: Collect some data</a></li>
<li class="chapter" data-level="9.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-3-specify-the-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>9.3.3</b> Step 3: Specify the null and alternative hypotheses</a></li>
<li class="chapter" data-level="9.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-4-fit-a-model-to-the-data-and-compute-a-test-statistic"><i class="fa fa-check"></i><b>9.3.4</b> Step 4: Fit a model to the data and compute a test statistic</a></li>
<li class="chapter" data-level="9.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-5-determine-the-probability-of-the-data-under-the-null-hypothesis"><i class="fa fa-check"></i><b>9.3.5</b> Step 5: Determine the probability of the data under the null hypothesis</a></li>
<li class="chapter" data-level="9.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-6-assess-the-statistical-significance-of-the-result"><i class="fa fa-check"></i><b>9.3.6</b> Step 6: Assess the “statistical significance” of the result</a></li>
<li class="chapter" data-level="9.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#what-does-a-significant-result-mean"><i class="fa fa-check"></i><b>9.3.7</b> What does a significant result mean?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#nhst-in-a-modern-context-multiple-testing"><i class="fa fa-check"></i><b>9.4</b> NHST in a modern context: Multiple testing</a></li>
<li class="chapter" data-level="9.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#suggested-readings-6"><i class="fa fa-check"></i><b>9.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html"><i class="fa fa-check"></i><b>10</b> Confidence intervals, effect sizes, and statistical power</a><ul>
<li class="chapter" data-level="10.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-1"><i class="fa fa-check"></i><b>10.1</b> Confidence intervals</a><ul>
<li class="chapter" data-level="10.1.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-normal-distribution"><i class="fa fa-check"></i><b>10.1.1</b> Confidence intervals using the normal distribution</a></li>
<li class="chapter" data-level="10.1.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-t-distribution"><i class="fa fa-check"></i><b>10.1.2</b> Confidence intervals using the t distribution</a></li>
<li class="chapter" data-level="10.1.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-and-sample-size"><i class="fa fa-check"></i><b>10.1.3</b> Confidence intervals and sample size</a></li>
<li class="chapter" data-level="10.1.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#computing-confidence-intervals-using-the-bootstrap"><i class="fa fa-check"></i><b>10.1.4</b> Computing confidence intervals using the bootstrap</a></li>
<li class="chapter" data-level="10.1.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#relation-of-confidence-intervals-to-hypothesis-tests"><i class="fa fa-check"></i><b>10.1.5</b> Relation of confidence intervals to hypothesis tests</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#effect-sizes"><i class="fa fa-check"></i><b>10.2</b> Effect sizes</a><ul>
<li class="chapter" data-level="10.2.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#cohens-d"><i class="fa fa-check"></i><b>10.2.1</b> Cohen’s D</a></li>
<li class="chapter" data-level="10.2.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#pearsons-r"><i class="fa fa-check"></i><b>10.2.2</b> Pearson’s r</a></li>
<li class="chapter" data-level="10.2.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#odds-ratio"><i class="fa fa-check"></i><b>10.2.3</b> Odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#statistical-power"><i class="fa fa-check"></i><b>10.3</b> Statistical power</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#power-analysis"><i class="fa fa-check"></i><b>10.3.1</b> Power analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#suggested-readings-7"><i class="fa fa-check"></i><b>10.4</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>11</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="11.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#generative-models"><i class="fa fa-check"></i><b>11.1</b> Generative models</a></li>
<li class="chapter" data-level="11.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-theorem-and-inverse-inference"><i class="fa fa-check"></i><b>11.2</b> Bayes’ theorem and inverse inference</a></li>
<li class="chapter" data-level="11.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#doing-bayesian-estimation"><i class="fa fa-check"></i><b>11.3</b> Doing Bayesian estimation</a><ul>
<li class="chapter" data-level="11.3.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior"><i class="fa fa-check"></i><b>11.3.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="11.3.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data"><i class="fa fa-check"></i><b>11.3.2</b> Collect some data</a></li>
<li class="chapter" data-level="11.3.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood"><i class="fa fa-check"></i><b>11.3.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="11.3.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood"><i class="fa fa-check"></i><b>11.3.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="11.3.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior"><i class="fa fa-check"></i><b>11.3.5</b> Computing the posterior</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#estimating-posterior-distributions"><i class="fa fa-check"></i><b>11.4</b> Estimating posterior distributions</a><ul>
<li class="chapter" data-level="11.4.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior-1"><i class="fa fa-check"></i><b>11.4.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="11.4.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data-1"><i class="fa fa-check"></i><b>11.4.2</b> Collect some data</a></li>
<li class="chapter" data-level="11.4.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood-1"><i class="fa fa-check"></i><b>11.4.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="11.4.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood-1"><i class="fa fa-check"></i><b>11.4.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="11.4.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior-1"><i class="fa fa-check"></i><b>11.4.5</b> Computing the posterior</a></li>
<li class="chapter" data-level="11.4.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#maximum-a-posteriori-map-estimation"><i class="fa fa-check"></i><b>11.4.6</b> Maximum a posteriori (MAP) estimation</a></li>
<li class="chapter" data-level="11.4.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#credible-intervals"><i class="fa fa-check"></i><b>11.4.7</b> Credible intervals</a></li>
<li class="chapter" data-level="11.4.8" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#effects-of-different-priors"><i class="fa fa-check"></i><b>11.4.8</b> Effects of different priors</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#choosing-a-prior"><i class="fa fa-check"></i><b>11.5</b> Choosing a prior</a></li>
<li class="chapter" data-level="11.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>11.6</b> Bayesian hypothesis testing</a><ul>
<li class="chapter" data-level="11.6.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-factors"><i class="fa fa-check"></i><b>11.6.1</b> Bayes factors</a></li>
<li class="chapter" data-level="11.6.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-factors-for-statistical-hypotheses"><i class="fa fa-check"></i><b>11.6.2</b> Bayes factors for statistical hypotheses</a></li>
<li class="chapter" data-level="11.6.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#assessing-evidence-for-the-null-hypothesis"><i class="fa fa-check"></i><b>11.6.3</b> Assessing evidence for the null hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#suggested-readings-8"><i class="fa fa-check"></i><b>11.7</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html"><i class="fa fa-check"></i><b>12</b> Modeling categorical relationships</a><ul>
<li class="chapter" data-level="12.1" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#example-candy-colors"><i class="fa fa-check"></i><b>12.1</b> Example: Candy colors</a></li>
<li class="chapter" data-level="12.2" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#pearsons-chi-squared-test"><i class="fa fa-check"></i><b>12.2</b> Pearson’s chi-squared test</a></li>
<li class="chapter" data-level="12.3" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#contingency-tables-and-the-two-way-test"><i class="fa fa-check"></i><b>12.3</b> Contingency tables and the two-way test</a></li>
<li class="chapter" data-level="12.4" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#standardized-residuals"><i class="fa fa-check"></i><b>12.4</b> Standardized residuals</a></li>
<li class="chapter" data-level="12.5" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#odds-ratios"><i class="fa fa-check"></i><b>12.5</b> Odds ratios</a></li>
<li class="chapter" data-level="12.6" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#bayes-factor"><i class="fa fa-check"></i><b>12.6</b> Bayes factor</a></li>
<li class="chapter" data-level="12.7" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#categorical-analysis-beyond-the-2-x-2-table"><i class="fa fa-check"></i><b>12.7</b> Categorical analysis beyond the 2 X 2 table</a></li>
<li class="chapter" data-level="12.8" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#beware-of-simpsons-paradox"><i class="fa fa-check"></i><b>12.8</b> Beware of Simpson’s paradox</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html"><i class="fa fa-check"></i><b>13</b> Modeling continuous relationships</a><ul>
<li class="chapter" data-level="13.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#an-example-hate-crimes-and-income-inequality"><i class="fa fa-check"></i><b>13.1</b> An example: Hate crimes and income inequality</a><ul>
<li class="chapter" data-level="13.1.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#quantifying-inequality-the-gini-index"><i class="fa fa-check"></i><b>13.1.1</b> Quantifying inequality: The Gini index</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#is-income-inequality-related-to-hate-crimes"><i class="fa fa-check"></i><b>13.2</b> Is income inequality related to hate crimes?</a></li>
<li class="chapter" data-level="13.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#covariance-and-correlation"><i class="fa fa-check"></i><b>13.3</b> Covariance and correlation</a><ul>
<li class="chapter" data-level="13.3.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#hypothesis-testing-for-correlations"><i class="fa fa-check"></i><b>13.3.1</b> Hypothesis testing for correlations</a></li>
<li class="chapter" data-level="13.3.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#robust-correlations"><i class="fa fa-check"></i><b>13.3.2</b> Robust correlations</a></li>
<li class="chapter" data-level="13.3.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#bayesian-correlation-analysis"><i class="fa fa-check"></i><b>13.3.3</b> Bayesian correlation analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#correlation-and-causation"><i class="fa fa-check"></i><b>13.4</b> Correlation and causation</a><ul>
<li class="chapter" data-level="13.4.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#causal-graphs"><i class="fa fa-check"></i><b>13.4.1</b> Causal graphs</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#suggested-readings-9"><i class="fa fa-check"></i><b>13.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html"><i class="fa fa-check"></i><b>14</b> The General Linear Model</a><ul>
<li class="chapter" data-level="14.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#linear-regression"><i class="fa fa-check"></i><b>14.1</b> Linear regression</a><ul>
<li class="chapter" data-level="14.1.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#regression-to-the-mean"><i class="fa fa-check"></i><b>14.1.1</b> Regression to the mean</a></li>
<li class="chapter" data-level="14.1.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#estimating-linear-regression-parameters"><i class="fa fa-check"></i><b>14.1.2</b> Estimating linear regression parameters</a></li>
<li class="chapter" data-level="14.1.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#the-relation-between-correlation-and-regression"><i class="fa fa-check"></i><b>14.1.3</b> The relation between correlation and regression</a></li>
<li class="chapter" data-level="14.1.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#standard-errors-for-regression-models"><i class="fa fa-check"></i><b>14.1.4</b> Standard errors for regression models</a></li>
<li class="chapter" data-level="14.1.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#statistical-tests-for-regression-parameters"><i class="fa fa-check"></i><b>14.1.5</b> Statistical tests for regression parameters</a></li>
<li class="chapter" data-level="14.1.6" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#quantifying-goodness-of-fit-of-the-model"><i class="fa fa-check"></i><b>14.1.6</b> Quantifying goodness of fit of the model</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#fitting-more-complex-models"><i class="fa fa-check"></i><b>14.2</b> Fitting more complex models</a></li>
<li class="chapter" data-level="14.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#interactions-between-variables"><i class="fa fa-check"></i><b>14.3</b> Interactions between variables</a></li>
<li class="chapter" data-level="14.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#what-does-predict-really-mean"><i class="fa fa-check"></i><b>14.4</b> What does “predict” really mean?</a><ul>
<li class="chapter" data-level="14.4.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#cross-validation"><i class="fa fa-check"></i><b>14.4.1</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#suggested-readings-10"><i class="fa fa-check"></i><b>14.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="comparing-means.html"><a href="comparing-means.html"><i class="fa fa-check"></i><b>15</b> Comparing means</a><ul>
<li class="chapter" data-level="15.1" data-path="comparing-means.html"><a href="comparing-means.html#students-t-test"><i class="fa fa-check"></i><b>15.1</b> Student’s T test</a></li>
<li class="chapter" data-level="15.2" data-path="comparing-means.html"><a href="comparing-means.html#the-t-test-as-a-linear-model"><i class="fa fa-check"></i><b>15.2</b> The t-test as a linear model</a><ul>
<li class="chapter" data-level="15.2.1" data-path="comparing-means.html"><a href="comparing-means.html#effect-sizes-for-comparing-two-means"><i class="fa fa-check"></i><b>15.2.1</b> Effect sizes for comparing two means</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="comparing-means.html"><a href="comparing-means.html#bayes-factor-for-mean-differences"><i class="fa fa-check"></i><b>15.3</b> Bayes factor for mean differences</a></li>
<li class="chapter" data-level="15.4" data-path="comparing-means.html"><a href="comparing-means.html#paired-t-tests"><i class="fa fa-check"></i><b>15.4</b> Paired t-tests</a><ul>
<li class="chapter" data-level="15.4.1" data-path="comparing-means.html"><a href="comparing-means.html#sign-test"><i class="fa fa-check"></i><b>15.4.1</b> Sign test</a></li>
<li class="chapter" data-level="15.4.2" data-path="comparing-means.html"><a href="comparing-means.html#paired-t-test"><i class="fa fa-check"></i><b>15.4.2</b> Paired t-test</a></li>
<li class="chapter" data-level="15.4.3" data-path="comparing-means.html"><a href="comparing-means.html#the-paired-t-test-as-a-linear-model"><i class="fa fa-check"></i><b>15.4.3</b> The paired t-test as a linear model</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="comparing-means.html"><a href="comparing-means.html#comparing-more-than-two-means"><i class="fa fa-check"></i><b>15.5</b> Comparing more than two means</a><ul>
<li class="chapter" data-level="15.5.1" data-path="comparing-means.html"><a href="comparing-means.html#analysis-of-variance"><i class="fa fa-check"></i><b>15.5.1</b> Analysis of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="practical-example.html"><a href="practical-example.html"><i class="fa fa-check"></i><b>16</b> The process of statistical modeling: A practical example</a><ul>
<li class="chapter" data-level="16.1" data-path="practical-example.html"><a href="practical-example.html#the-process-of-statistical-modeling"><i class="fa fa-check"></i><b>16.1</b> The process of statistical modeling</a><ul>
<li class="chapter" data-level="16.1.1" data-path="practical-example.html"><a href="practical-example.html#specify-your-question-of-interest"><i class="fa fa-check"></i><b>16.1.1</b> 1: Specify your question of interest</a></li>
<li class="chapter" data-level="16.1.2" data-path="practical-example.html"><a href="practical-example.html#identify-or-collect-the-appropriate-data"><i class="fa fa-check"></i><b>16.1.2</b> 2: Identify or collect the appropriate data</a></li>
<li class="chapter" data-level="16.1.3" data-path="practical-example.html"><a href="practical-example.html#prepare-the-data-for-analysis"><i class="fa fa-check"></i><b>16.1.3</b> 3: Prepare the data for analysis</a></li>
<li class="chapter" data-level="16.1.4" data-path="practical-example.html"><a href="practical-example.html#determine-the-appropriate-model"><i class="fa fa-check"></i><b>16.1.4</b> 4. Determine the appropriate model</a></li>
<li class="chapter" data-level="16.1.5" data-path="practical-example.html"><a href="practical-example.html#fit-the-model-to-the-data"><i class="fa fa-check"></i><b>16.1.5</b> 5. Fit the model to the data</a></li>
<li class="chapter" data-level="16.1.6" data-path="practical-example.html"><a href="practical-example.html#criticize-the-model-to-make-sure-it-fits-properly"><i class="fa fa-check"></i><b>16.1.6</b> 6. Criticize the model to make sure it fits properly</a></li>
<li class="chapter" data-level="16.1.7" data-path="practical-example.html"><a href="practical-example.html#test-hypothesis-and-quantify-effect-size"><i class="fa fa-check"></i><b>16.1.7</b> 7. Test hypothesis and quantify effect size</a></li>
<li class="chapter" data-level="16.1.8" data-path="practical-example.html"><a href="practical-example.html#what-about-possible-confounds"><i class="fa fa-check"></i><b>16.1.8</b> What about possible confounds?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html"><i class="fa fa-check"></i><b>17</b> Doing reproducible research</a><ul>
<li class="chapter" data-level="17.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-we-think-science-should-work"><i class="fa fa-check"></i><b>17.1</b> How we think science should work</a></li>
<li class="chapter" data-level="17.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-science-sometimes-actually-works"><i class="fa fa-check"></i><b>17.2</b> How science (sometimes) actually works</a></li>
<li class="chapter" data-level="17.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-reproducibility-crisis-in-science"><i class="fa fa-check"></i><b>17.3</b> The reproducibility crisis in science</a><ul>
<li class="chapter" data-level="17.3.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#positive-predictive-value-and-statistical-significance"><i class="fa fa-check"></i><b>17.3.1</b> Positive predictive value and statistical significance</a></li>
<li class="chapter" data-level="17.3.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-winners-curse"><i class="fa fa-check"></i><b>17.3.2</b> The winner’s curse</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#questionable-research-practices"><i class="fa fa-check"></i><b>17.4</b> Questionable research practices</a><ul>
<li class="chapter" data-level="17.4.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#esp-or-qrp"><i class="fa fa-check"></i><b>17.4.1</b> ESP or QRP?</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-research-1"><i class="fa fa-check"></i><b>17.5</b> Doing reproducible research</a><ul>
<li class="chapter" data-level="17.5.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#pre-registration"><i class="fa fa-check"></i><b>17.5.1</b> Pre-registration</a></li>
<li class="chapter" data-level="17.5.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#reproducible-practices"><i class="fa fa-check"></i><b>17.5.2</b> Reproducible practices</a></li>
<li class="chapter" data-level="17.5.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#replication"><i class="fa fa-check"></i><b>17.5.3</b> Replication</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-data-analysis"><i class="fa fa-check"></i><b>17.6</b> Doing reproducible data analysis</a></li>
<li class="chapter" data-level="17.7" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#conclusion-doing-better-science"><i class="fa fa-check"></i><b>17.7</b> Conclusion: Doing better science</a></li>
<li class="chapter" data-level="17.8" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#suggested-readings-11"><i class="fa fa-check"></i><b>17.8</b> Suggested Readings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Thinking for the 21st Century</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modeling-categorical-relationships" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Modeling categorical relationships</h1>
<p>So far we have discussed the general concept of statistical modeling and hypothesis testing, and applied them to some simple analyses. In this chapter we will focus on the modeling of <em>categorical</em> relationships, by which we mean relationships between variables that are measured on a nominal (and sometimes ordinal) scale. These data are usually expressed in terms of counts; that is, for each value of the variable (or combination of values of multiple variables), how many observations take that value? For example, when we count how many people from each major are in our class, we are fitting a categorical model to the data.</p>
<div id="example-candy-colors" class="section level2">
<h2><span class="header-section-number">12.1</span> Example: Candy colors</h2>
<p>Let’s say that I have purchased a bag of 100 candies, which are labeled as having 1/3 chocolates, 1/3 licorices, and 1/3 gumballs. When I count the candies in the bag, we get the following numbers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">candyDf &lt;-
<span class="st">  </span><span class="kw">tibble</span>(
    <span class="dt">candyType =</span> <span class="kw">c</span>(<span class="st">&quot;chocolate&quot;</span>, <span class="st">&quot;licorice&quot;</span>, <span class="st">&quot;gumball&quot;</span>),
    <span class="dt">count =</span> <span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">33</span>, <span class="dv">37</span>)
  )
<span class="kw">pander</span>(candyDf)</code></pre></div>
<table style="width:26%;">
<colgroup>
<col width="16%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">candyType</th>
<th align="center">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">chocolate</td>
<td align="center">30</td>
</tr>
<tr class="even">
<td align="center">licorice</td>
<td align="center">33</td>
</tr>
<tr class="odd">
<td align="center">gumball</td>
<td align="center">37</td>
</tr>
</tbody>
</table>
<p>Because I like chocolate much more than licorice or gumballs, I feel slightly ripped off. What I would like to know is: What is the likelihood that the count would come out this way if the true probability of each candy type is the averaged proportion of 1/3 each?</p>
</div>
<div id="pearsons-chi-squared-test" class="section level2">
<h2><span class="header-section-number">12.2</span> Pearson’s chi-squared test</h2>
<p>The Pearson chi-squared test provides us with a way to test whether observed count data differs from some specific expected values that define the null hypothesis:</p>
<p><span class="math display">\[
\chi^2 = \sum_i\frac{(observed_i - expected_i)^2}{expected_i}
\]</span></p>
<p>In the case of our candy example, the null hypothesis is that the proportion of each type of candies is equal. We can compute the chi-squared statistic for our observed counts of candy as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute chi-squared statistic</span>

nullExpectation &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(candyDf<span class="op">$</span>count)

chisqVal &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">sum</span>(
    ((candyDf<span class="op">$</span>count <span class="op">-</span><span class="st"> </span>nullExpectation)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>nullExpectation
  )</code></pre></div>
<p>The chi-squared statistic for this analysis comes out to 0.74, which on its own is not interpretable, since it depends on the number of different values that were added together. However, we can take advantage of the fact that the chi-squared statistic is distributed according to a specific distribution under the null hypothesis, which is known as the <em>chi-squared</em> distribution. This distribution is defined as the sum of squares of a set of standard normal random variables; it has a number of degrees of freedom that is equal to the number of variables being added together. The shape of the distribution depends on the number of degrees of freedom. Figure <a href="modeling-categorical-relationships.html#fig:chisqDist">12.1</a> shows examples of the distribution for several different degrees of freedom.</p>
<div class="figure"><span id="fig:chisqDist"></span>
<img src="StatsThinking21_files/figure-html/chisqDist-1.png" alt="Examples of the chi-squared distribution for various degrees of freedom." width="384" height="50%" />
<p class="caption">
Figure 12.1: Examples of the chi-squared distribution for various degrees of freedom.
</p>
</div>
<p>Let’s verify that the chi-squared distribution accurately describes the sum of squares of a set of standard normal random variables, using simulation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate 50,000 sums of 8 standard normal random variables and compare</span>
<span class="co"># to theoretical chi-squared distribution</span>

<span class="co"># create a matrix with 50k columns of 8 rows of squared normal random variables</span>
d &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">50000</span>, <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">8</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)<span class="op">**</span><span class="dv">2</span>) 
<span class="co"># sum each column of 8 variables</span>
dMean &lt;-<span class="st"> </span><span class="kw">apply</span>(d, <span class="dv">2</span>, sum)

<span class="co"># create a data frame of the theoretical chi-square distribution </span>
<span class="co"># with 8 degrees of freedom</span>
csDf &lt;-
<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="dv">30</span>, <span class="fl">0.01</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">chisq =</span> <span class="kw">dchisq</span>(x, <span class="dv">8</span>))</code></pre></div>
<p>Figure <a href="modeling-categorical-relationships.html#fig:chisqSim">12.2</a> shows that the theoretical distribution matches closely with the results of a simulation that repeatedly added</p>
<div class="figure"><span id="fig:chisqSim"></span>
<img src="StatsThinking21_files/figure-html/chisqSim-1.png" alt="Simulation of sum of squared random normal variables.   The histogram is based on the sum of squares of 50,000 sets of 8 random normal variables; the blue line shows the values of the theoretical chi-squared distribution with 8 degrees of freedom." width="384" height="50%" />
<p class="caption">
Figure 12.2: Simulation of sum of squared random normal variables. The histogram is based on the sum of squares of 50,000 sets of 8 random normal variables; the blue line shows the values of the theoretical chi-squared distribution with 8 degrees of freedom.
</p>
</div>
<p>For the candy example, we can compute the likelihood of our observed chi-squared value of 0.74 under the null hypothesis of equal frequency across all candies. We use a chi-squared distribution with degrees of freedom equal to n - 1, since we lost one degree of freedom when we computed the mean in order to generate the expected values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chisqVal, <span class="dt">df =</span> <span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>) <span class="co">#df = degrees of freedom</span>
<span class="kw">sprintf</span>(<span class="st">&quot;p-value = %0.3f&quot;</span>, pval)</code></pre></div>
<pre><code>## [1] &quot;p-value = 0.691&quot;</code></pre>
<p>This shows that the observed counts of candies are not particularly surprising based on the proportions printed on the bag of candy, and we would not reject the null hypothesis of equal proportions.</p>
</div>
<div id="contingency-tables-and-the-two-way-test" class="section level2">
<h2><span class="header-section-number">12.3</span> Contingency tables and the two-way test</h2>
<p>Another way that we often use the chi-squared test is to ask whether two categorical variables are related to one another. As a more realistic example, let’s take the question of whether a black driver is more likely to be searched when they are pulled over by a police officer, compared to a white driver The Stanford Open Policing Project (<a href="https://openpolicing.stanford.edu/" class="uri">https://openpolicing.stanford.edu/</a>) has studied this, and provides data that we can use to analyze the question. We will use the data from the State of Connecticut since they are fairly small. These data were first cleaned up to remove all unnecessary data (see code/process_CT_data.py).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load police stop data</span>
stopData &lt;-
<span class="st">  </span><span class="kw">read_csv</span>(<span class="st">&quot;data/CT_data_cleaned.csv&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">searched =</span> search_conducted)</code></pre></div>
<p>The standard way to represent data from a categorical analysis is through a <em>contingency table</em>, which presents the number or proportion of observations falling into each possible combination of values for each of the variables.</p>
<p>Let’s compute the contingency table for the police search data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute and print two-way contingency table</span>
summaryDf2way &lt;-
<span class="st">  </span>stopData <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(searched, driver_race) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(driver_race, searched) 

summaryContingencyTable &lt;-
<span class="st">  </span>summaryDf2way <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(driver_race, n)

<span class="kw">pander</span>(summaryContingencyTable)</code></pre></div>
<table style="width:38%;">
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">searched</th>
<th align="center">Black</th>
<th align="center">White</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">36244</td>
<td align="center">239241</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">1219</td>
<td align="center">3108</td>
</tr>
</tbody>
</table>
<p>It can also be useful to look at the contingency table using proportions rather than raw numbers, since they are easier to compare visually.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Compute and print contingency table using proportions </span>
<span class="co"># rather than raw frequencies</span>
summaryContingencyTableProportion &lt;-
<span class="st">  </span>summaryContingencyTable <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">Black =</span> Black <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(stopData), <span class="co">#count of Black individuals searched / total searched</span>
    <span class="dt">White =</span> White <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(stopData)
  )
<span class="kw">pander</span>(summaryContingencyTableProportion, <span class="dt">round =</span> <span class="dv">4</span>)</code></pre></div>
<table style="width:40%;">
<colgroup>
<col width="15%" />
<col width="12%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">searched</th>
<th align="center">Black</th>
<th align="center">White</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">0.1295</td>
<td align="center">0.855</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">0.0044</td>
<td align="center">0.0111</td>
</tr>
</tbody>
</table>
<p>The Pearson chi-squared test allows us to test whether observed frequencies are different from expected frequencies, so we need to determine what frequencies we would expect in each cell if searches and race were unrelated – which we can define as being <em>independent.</em> Remember from the chapter on probability that if X and Y are independent, then:</p>
<p><span class="math display">\[
P(X \cap Y) = P(X) * P(Y)
\]</span> That is, the joint probability under the null hypothesis of independence is simply the product of the <em>marginal</em> probabilities of each individual variable. The marginal probabilities are simply the probabilities of each event occuring regardless of other events. We can compute those marginal probabilities, and then multiply them together to get the expected proportions under independence.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Black</th>
<th>White</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Not searched</td>
<td>P(NS)*P(B)</td>
<td>P(NS)*P(W)</td>
<td>P(NS)</td>
</tr>
<tr class="even">
<td>Searched</td>
<td>P(S)*P(B)</td>
<td>P(S)*P(W)</td>
<td>P(S)</td>
</tr>
<tr class="odd">
<td></td>
<td>P(B)</td>
<td>P(W)</td>
<td></td>
</tr>
</tbody>
</table>
<p>We can use a linear algebra trick known as the “outer product” (via the <code>outer()</code> function) to compute this easily.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># first, compute the marginal probabilities</span>

<span class="co"># probability of being each race</span>
summaryDfRace &lt;-
<span class="st">  </span>stopData <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(driver_race) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">#count the number of drivers of each race</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prop =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n) <span class="co">#compute the proportion of each race out of all drivers</span>
  )

<span class="co"># probability of being searched </span>
summaryDfStop &lt;-
<span class="st">  </span>stopData <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(searched) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">#count the number of searched vs. not searched</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prop =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n) <span class="co"># compute proportion of each outcome out all traffic stops</span>
  )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># second, multiply outer product by n (all stops) to compute expected frequencies</span>
expected &lt;-<span class="st"> </span><span class="kw">outer</span>(summaryDfRace<span class="op">$</span>prop, summaryDfStop<span class="op">$</span>prop) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(stopData)

<span class="co"># create a data frame of expected frequences for each race </span>
expectedDf &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>(expected, <span class="dt">driverRace =</span> <span class="kw">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;White&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(
    <span class="dt">NotSearched =</span> X1,
    <span class="dt">Searched =</span> X2
  )

<span class="co"># tidy the data frame</span>
expectedDfTidy &lt;-
<span class="st">  </span><span class="kw">gather</span>(expectedDf, searched, n, <span class="op">-</span>driverRace) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(driverRace, searched)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># third, add expected frequencies to the original summary table</span>
<span class="co"># and fourth, compute the standardized squared difference between </span>
<span class="co"># the observed and expected frequences</span>

summaryDf2way &lt;-
<span class="st">  </span>summaryDf2way <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">expected =</span> expectedDfTidy<span class="op">$</span>n)

summaryDf2way &lt;-
<span class="st">  </span>summaryDf2way <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">stdSqDiff =</span> (n <span class="op">-</span><span class="st"> </span>expected)<span class="op">**</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>expected)

<span class="kw">pander</span>(summaryDf2way)</code></pre></div>
<table style="width:78%;">
<colgroup>
<col width="15%" />
<col width="19%" />
<col width="12%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">searched</th>
<th align="center">driver_race</th>
<th align="center">n</th>
<th align="center">expected</th>
<th align="center">stdSqDiff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">Black</td>
<td align="center">36244</td>
<td align="center">36883.67</td>
<td align="center">11.09</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">Black</td>
<td align="center">1219</td>
<td align="center">579.33</td>
<td align="center">706.31</td>
</tr>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">White</td>
<td align="center">239241</td>
<td align="center">238601.3</td>
<td align="center">1.71</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">White</td>
<td align="center">3108</td>
<td align="center">3747.67</td>
<td align="center">109.18</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># finally, compute chi-squared statistic by </span>
<span class="co"># summing the standarized squared differences</span>
chisq &lt;-<span class="st"> </span><span class="kw">sum</span>(summaryDf2way<span class="op">$</span>stdSqDiff)
<span class="kw">sprintf</span>(<span class="st">&quot;Chi-squared value = %0.2f&quot;</span>, chisq)</code></pre></div>
<pre><code>## [1] &quot;Chi-squared value = 828.30&quot;</code></pre>
<p>Having computed the chi-squared statistic, we now need to compare it to the chi-squared distribution in order to determine how extreme it is compared to our expectation under the null hypothesis. The degrees of freedom for this distribution are <span class="math inline">\(df = (nRows - 1) * (nColumns - 1)\)</span> - thus, for a 2X2 table like the one here, <span class="math inline">\(df = (2-1)*(2-1)=1\)</span>. The intuition here is that computing the expected frequencies requires us to use three values: the total number of observations and the marginal probability for each of the two variables. Thus, once those values are computed, there is only one number that is free to vary, and thus there is one degree of freedom. Given this, we can compute the p-value for the chi-squared statistic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chisq, <span class="dt">df =</span> <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
<span class="kw">sprintf</span>(<span class="st">&quot;p-value = %e&quot;</span>, pval)</code></pre></div>
<pre><code>## [1] &quot;p-value = 3.795669e-182&quot;</code></pre>
<p>The p value of <span class="math inline">\(3.79e^{-182}\)</span> is exceedingly small, showing that the observed data would be highly unlikely if there was truly no relationship between race and police searches, and thus we should reject the null hypothesis of independence.</p>
<p>We can also perform this test easily using the <code>chisq.test()</code> function in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># first need to rearrange the data into a 2x2 table</span>
summaryDf2wayTable &lt;-
<span class="st">  </span>summaryDf2way <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>expected, <span class="op">-</span>stdSqDiff) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(searched, n) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>driver_race)

chisqTestResult &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(summaryDf2wayTable, <span class="dv">1</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)
chisqTestResult</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  summaryDf2wayTable
## X-squared = 800, df = 1, p-value &lt;2e-16</code></pre>
</div>
<div id="standardized-residuals" class="section level2">
<h2><span class="header-section-number">12.4</span> Standardized residuals</h2>
<p>When we find a significant effect with the chi-squared test, this tells us that the data are unlikely under the null hypothesis, but it doesn’t tell us <em>how</em> the data differ. To get a deeper insight into how the data differ from what we would expect under the null hypothesis, we can examine the residuals from a model, which reflects the deviation of the data (i.e., the observed frequencies) from the model in each cell (i.e., the expected frequencies). Rather than looking at the raw residuals (which will vary simply depending on the number of observations in the data), it’s more common to look at ther <em>standardized residuals</em>, which are computed as:</p>
<p><span class="math display">\[
standardized\ residual_{ij} = \frac{observed_{ij} - expected_{ij}}{\sqrt{expected_{ij}}}
\]</span> where <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are the indices for the rows and columns respectively. We can compute these for the police stop data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute standardized residuals</span>
summaryDf2way &lt;-<span class="st"> </span>
<span class="st">  </span>summaryDf2way <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">stdRes =</span> (n <span class="op">-</span><span class="st"> </span>expected)<span class="op">/</span><span class="kw">sqrt</span>(expected))

<span class="kw">pander</span>(summaryDf2way)</code></pre></div>
<table style="width:90%;">
<colgroup>
<col width="15%" />
<col width="19%" />
<col width="12%" />
<col width="15%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">searched</th>
<th align="center">driver_race</th>
<th align="center">n</th>
<th align="center">expected</th>
<th align="center">stdSqDiff</th>
<th align="center">stdRes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">Black</td>
<td align="center">36244</td>
<td align="center">36883.67</td>
<td align="center">11.09</td>
<td align="center">-3.33</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">Black</td>
<td align="center">1219</td>
<td align="center">579.33</td>
<td align="center">706.31</td>
<td align="center">26.58</td>
</tr>
<tr class="odd">
<td align="center">FALSE</td>
<td align="center">White</td>
<td align="center">239241</td>
<td align="center">238601.3</td>
<td align="center">1.71</td>
<td align="center">1.31</td>
</tr>
<tr class="even">
<td align="center">TRUE</td>
<td align="center">White</td>
<td align="center">3108</td>
<td align="center">3747.67</td>
<td align="center">109.18</td>
<td align="center">-10.45</td>
</tr>
</tbody>
</table>
<p>These standardized residuals can be interpreted as Z scores – in this case, we see that the number of searches for black individuals are substantially higher than expected based on independence, and the number of searches for white individuals are substantially lower than expected. This provides us with the context that we need to interpret the signficant chi-squared result.</p>
</div>
<div id="odds-ratios" class="section level2">
<h2><span class="header-section-number">12.5</span> Odds ratios</h2>
<p>We can also represent the relative likelihood of different outcomes in the contingency table using the odds ratio that we introduced earlier, in order to better understand the size of the effect. First, we represent the odds of being stopped for each race:</p>
<p><span class="math display">\[
odds_{searched|black} = \frac{N_{searched\cap black}}{N_{not\ searched\cap black}} = \frac{1219}{36244} = 0.034
\]</span></p>
<p><span class="math display">\[
odds_{searched|white} = \frac{N_{searched\cap white}}{N_{not\ searched\cap white}} = \frac{3108}{239241} = 0.013
\]</span> <span class="math display">\[
odds\ ratio = \frac{odds_{searched|black}}{odds_{searched|white}} = 2.59
\]</span></p>
<p>The odds ratio shows that the odds of being searched are 2.59 times higher for black versus white drivers, based on this dataset.</p>
</div>
<div id="bayes-factor" class="section level2">
<h2><span class="header-section-number">12.6</span> Bayes factor</h2>
<p>We discussed Bayes factors in the earlier chapter on Bayesian statistics – you may remember that it represents the ratio of the likelihood of the data under each of the two hypotheses: <span class="math display">\[ 
K = \frac{P(data|H_A)}{P(data|H_0)} = \frac{P(H_A|data)*P(H_A)}{P(H_0|data)*P(H_0)}
\]</span> Bayes factors are similar to p-values and effect sizes in one way, which is that their interpretation is somewhat subjective. There are various guidelines for their interpretation – here is one from <span class="citation">Kass and Raftery (1995)</span> :</p>
<table>
<thead>
<tr class="header">
<th>BF</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 to 3</td>
<td>barely worth mention</td>
</tr>
<tr class="even">
<td>3 to 20</td>
<td>positive</td>
</tr>
<tr class="odd">
<td>20 to 150</td>
<td>strong</td>
</tr>
<tr class="even">
<td>150 and above</td>
<td>very strong</td>
</tr>
</tbody>
</table>
<p>We can compute the Bayes factor for the police search data using the <code>contingencyTableBF()</code> function from the BayesFactor package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute Bayes factor </span>
<span class="co"># using independent multinomial sampling plan in which row totals (driver race)</span>
<span class="co"># are fixed</span>

bf &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">contingencyTableBF</span>(<span class="kw">as.matrix</span>(summaryDf2wayTable),
  <span class="dt">sampleType =</span> <span class="st">&quot;indepMulti&quot;</span>,
  <span class="dt">fixedMargin =</span> <span class="st">&quot;cols&quot;</span>
)
bf</code></pre></div>
<pre><code>## Bayes factor analysis
## --------------
## [1] Non-indep. (a=1) : 1.8e+142 ±0%
## 
## Against denominator:
##   Null, independence, a = 1 
## ---
## Bayes factor type: BFcontingencyTable, independent multinomial</code></pre>
<p>This shows that the evidence in favor of a relationship between driver race and police searches in this dataset is exceedingly strong.</p>
</div>
<div id="categorical-analysis-beyond-the-2-x-2-table" class="section level2">
<h2><span class="header-section-number">12.7</span> Categorical analysis beyond the 2 X 2 table</h2>
<p>Categorical analysis can also be applied to contingency tables where there are more than two categories for each variable.</p>
<p>For example, let’s look at the NHANES data and compare the variable <em>Depressed</em> which denotes the “self-reported number of days where participant felt down, depressed or hopeless”. This variable is coded as <code>None</code>, <code>Several</code>, or <code>Most</code>. Let’s test whether this variable is related to the <em>SleepTrouble</em> variable which reports whether the individual has reported sleeping problems to a doctor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># summarize depression as a function of sleep trouble</span>
depressedSleepTrouble &lt;-
<span class="st">  </span>NHANES_adult <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(SleepTrouble, Depressed) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(SleepTrouble, Depressed) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(SleepTrouble, Depressed)

depressedSleepTroubleTable &lt;-
<span class="st">  </span>depressedSleepTrouble <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(SleepTrouble, n) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(
    <span class="dt">NoSleepTrouble =</span> No,
    <span class="dt">YesSleepTrouble =</span> Yes
  )

<span class="kw">pander</span>(depressedSleepTroubleTable)</code></pre></div>
<table style="width:64%;">
<colgroup>
<col width="16%" />
<col width="23%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Depressed</th>
<th align="center">NoSleepTrouble</th>
<th align="center">YesSleepTrouble</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">None</td>
<td align="center">2614</td>
<td align="center">676</td>
</tr>
<tr class="even">
<td align="center">Several</td>
<td align="center">418</td>
<td align="center">249</td>
</tr>
<tr class="odd">
<td align="center">Most</td>
<td align="center">138</td>
<td align="center">145</td>
</tr>
</tbody>
</table>
<p>Simply by looking at these data, we can tell that it is likely that there is a relationship between the two variables; notably, while the total number of people with sleep trouble is much less than those without, for people who report being depresssed most days the number with sleep problems is greater than those without. We can quantify this directly using the chi-squared test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># need to remove the column with the label names</span>
depressedSleepTroubleTable &lt;-
<span class="st">  </span>depressedSleepTroubleTable <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>Depressed)

depressedSleepChisq &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(depressedSleepTroubleTable)
depressedSleepChisq</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  depressedSleepTroubleTable
## X-squared = 200, df = 2, p-value &lt;2e-16</code></pre>
<p>This test shows that there is a strong relationship between depression and sleep trouble. We can also compute the Bayes factor to quantify the strength of the evidence in favor the alternative hypothesis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute bayes factor, using a joint multinomial sampling plan</span>
bf &lt;-
<span class="st">  </span><span class="kw">contingencyTableBF</span>(
    <span class="kw">as.matrix</span>(depressedSleepTroubleTable),
    <span class="dt">sampleType =</span> <span class="st">&quot;jointMulti&quot;</span>
  )
bf</code></pre></div>
<pre><code>## Bayes factor analysis
## --------------
## [1] Non-indep. (a=1) : 1.8e+35 ±0%
## 
## Against denominator:
##   Null, independence, a = 1 
## ---
## Bayes factor type: BFcontingencyTable, joint multinomial</code></pre>
<p>Here see that the Bayes factor is exceedingly large, showing that the evidence in favor of a relation between depression and sleep problems is very strong.</p>
</div>
<div id="beware-of-simpsons-paradox" class="section level2">
<h2><span class="header-section-number">12.8</span> Beware of Simpson’s paradox</h2>
<p>The contingency tables presented above represent summaries of large numbers of observations, but summaries can sometimes be misleading. Let’s take an example from baseball. The table below shows the batting data (hits/at bats and batting average) for Derek Jeter and David Justice over the years 1995-1997:</p>
<table>
<thead>
<tr class="header">
<th>Player</th>
<th>1995</th>
<th></th>
<th>1996</th>
<th></th>
<th>1997</th>
<th></th>
<th>Combined</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Derek Jeter</td>
<td>12/48</td>
<td>.250</td>
<td>183/582</td>
<td>.314</td>
<td>190/654</td>
<td>.291</td>
<td>385/1284</td>
<td><strong>.300</strong></td>
</tr>
<tr class="even">
<td>David Justice</td>
<td>104/411</td>
<td><strong>.253</strong></td>
<td>45/140</td>
<td><strong>.321</strong></td>
<td>163/495</td>
<td><strong>.329</strong></td>
<td>312/1046</td>
<td>.298</td>
</tr>
</tbody>
</table>
<p>If you look closely, you will see that something odd is going on: In each individual year Justice had a higher batting average than Jeter, but when we combine the data across all three years, Jeter’s average is actually higher than Justice’s! This is an example of a phenomenon known as <em>Simpson’s paradox</em>, in which a pattern that is present in a combined dataset may not be present in any of the subsets of the data. This occurs when there is another variable that may be changing across the different subsets – in this case, the number of at-bats varies across years, with Justice batting many more times in 1995 (when batting averages were low). We refer to this as a <em>lurking variable</em>, and it’s always important to be attentive to such variables whenever one examines categorical data.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modeling-continuous-relationships.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/poldrack/psych10-book/edit/master/12-CategoricalRelationships.Rmd",
"text": "Edit"
},
"download": ["StatsThinking21.pdf", "StatsThinking21.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
